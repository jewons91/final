{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price threshold 변경 (수수료 생각해서 손해보지 않을만큼 상승을 기준으로 파악)\n",
    "#### 다시 삼진분류\n",
    "#### Focal_loss\n",
    "#### num_head 8\n",
    "#### ff_dim 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('./000660.csv')\n",
    "\n",
    "# 데이터 칼럼명 변경\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        '시가': 'Open',\n",
    "        '고가': 'High',\n",
    "        '저가': 'Low',\n",
    "        '종가': 'Close',\n",
    "        '거래량': 'Total_Volume',\n",
    "        '매도량': 'Sell_Volume',\n",
    "        '매수량': 'Buy_Volume'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 선택\n",
    "price_features = ['Open', 'High', 'Low', 'Close']\n",
    "volume_features = ['Buy_Volume', 'Sell_Volume', 'Total_Volume']\n",
    "features = price_features + volume_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래량 강도 계산\n",
    "data['Volume_Intensity'] = data['Buy_Volume'] - data['Sell_Volume']\n",
    "data['Volume_Intensity_Ratio'] = data['Volume_Intensity'] / (data['Total_Volume'] + 1e-5)\n",
    "data['Buy_Sell_Ratio'] = data['Buy_Volume'] / (data['Sell_Volume'] + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 특성들을 특성 리스트에 추가\n",
    "features.extend(['Volume_Intensity', 'Volume_Intensity_Ratio', 'Buy_Sell_Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균선 추가\n",
    "data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
    "data['MA_20'] = data['Close'].rolling(window=20).mean()\n",
    "data['MA_60'] = data['Close'].rolling(window=60).mean()\n",
    "data['MA_5_20_Diff'] = data['MA_5'] - data['MA_20']\n",
    "data['MA_20_60_Diff'] = data['MA_20'] - data['MA_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가된 특성을 특성 리스트에 포함\n",
    "features.extend(['MA_5', 'MA_20', 'MA_60', 'MA_5_20_Diff', 'MA_20_60_Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균선 계산 후 결측치 제거\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 급변 레이블링\n",
    "price_threshold = 0.00  # 0.5% 이상 변동 시 급변으로 간주\n",
    "\n",
    "data['Price_Change'] = data['Close'].pct_change()\n",
    "data = data.dropna()\n",
    "\n",
    "def label_price_change(change):\n",
    "    if change >= price_threshold:\n",
    "        return 2  # 상승\n",
    "    elif change <= -price_threshold:\n",
    "        return 0  # 하락\n",
    "    else:\n",
    "        return 1  # 보합\n",
    "\n",
    "data['Price_Label'] = data['Price_Change'].apply(label_price_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거 (최종)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 딕셔너리 생성\n",
    "scalers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 관련 특성 스케일링\n",
    "for feature in price_features + ['MA_5', 'MA_20', 'MA_60', 'MA_5_20_Diff', 'MA_20_60_Diff']:\n",
    "    scaler = StandardScaler()\n",
    "    data[feature] = scaler.fit_transform(data[[feature]])\n",
    "    scalers[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래량 관련 특성 스케일링\n",
    "for feature in volume_features + ['Volume_Intensity', 'Volume_Intensity_Ratio', 'Buy_Sell_Ratio']:\n",
    "    scaler = RobustScaler()\n",
    "    data[feature] = scaler.fit_transform(data[[feature]])\n",
    "    scalers[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 생성 함수 정의\n",
    "def create_sequences(data, sequence_length, expect, target):\n",
    "    X = []\n",
    "    y = []\n",
    "    data_values = data[features].values\n",
    "    labels = data[target].values\n",
    "    for i in range(len(data_values) - sequence_length - expect + 1):\n",
    "        X.append(data_values[i:i+sequence_length])\n",
    "        y.append(labels[i+sequence_length + expect - 1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "sequence_length = 60  # 시퀀스 길이\n",
    "expect = 10\n",
    "X, y = create_sequences(data, sequence_length, target='Price_Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 순서대로 데이터 분할\n",
    "train_size = int(len(X) * 0.7)\n",
    "val_size = int(len(X) * 0.15)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "X_val = X[train_size:train_size+val_size]\n",
    "y_val = y[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X[train_size+val_size:]\n",
    "y_test = y[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 분포: {0: 203, 1: 130158, 2: 259}\n"
     ]
    }
   ],
   "source": [
    "# 클래스 분포 확인\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"클래스 분포:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "d_model = X_train.shape[2]\n",
    "num_heads = 8\n",
    "ff_dim = 128\n",
    "num_layers = 2\n",
    "dropout_rate = 0.1\n",
    "num_classes = 3  # 레이블 클래스 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 정의\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(sequence_length, d_model)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            np.arange(position)[:, np.newaxis],\n",
    "            np.arange(d_model)[np.newaxis, :],\n",
    "            d_model)\n",
    "        \n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 블록 정의\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attn_output = layers.Dropout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "    \n",
    "    # Feed Forward Network\n",
    "    ffn_output = layers.Dense(ff_dim, activation='gelu', kernel_regularizer=regularizers.l2(1e-4))(out1)\n",
    "    ffn_output = layers.Dense(head_size)(ffn_output)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "def create_model():\n",
    "    inputs = layers.Input(shape=(sequence_length, d_model))\n",
    "    x = PositionalEncoding(sequence_length, d_model)(inputs)\n",
    "    \n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_block(x, d_model, num_heads, ff_dim, dropout_rate)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 60, 15)]     0           []                               \n",
      "                                                                                                  \n",
      " positional_encoding (Positiona  (None, 60, 15)      0           ['input_1[0][0]']                \n",
      " lEncoding)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 60, 15)      7575        ['positional_encoding[0][0]',    \n",
      " dAttention)                                                      'positional_encoding[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 60, 15)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 60, 15)      0           ['positional_encoding[0][0]',    \n",
      " da)                                                              'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 60, 15)      30          ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 128)      2048        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 15)       1935        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 60, 15)       0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 60, 15)      0           ['layer_normalization[0][0]',    \n",
      " mbda)                                                            'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 60, 15)      30          ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 60, 15)      7575        ['layer_normalization_1[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 60, 15)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 60, 15)      0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 60, 15)      30          ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 128)      2048        ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 15)       1935        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 60, 15)       0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 60, 15)      0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 60, 15)      30          ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 15)          0           ['layer_normalization_3[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 15)           0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 3)            48          ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,284\n",
      "Trainable params: 23,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9.974799541809851, 1: 0.3578414451731676, 2: 9.504475005457325}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss 구현\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, dtype='int32')\n",
    "        y_true = K.one_hot(y_true, num_classes)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = - y_true * alpha * K.pow(1 - y_pred, gamma) * K.log(y_pred)\n",
    "        loss = K.sum(loss, axis=-1)\n",
    "        return K.mean(loss)\n",
    "    \n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    loss=focal_loss(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 체크포인트 콜백 설정\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model_transformer2/best_model_2_09.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 리스트에 포함\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    checkpoint_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9307\n",
      "Epoch 1: val_loss improved from inf to 0.03098, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 159s 19ms/step - loss: 0.0484 - accuracy: 0.9307 - val_loss: 0.0310 - val_accuracy: 0.9437\n",
      "Epoch 2/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9315\n",
      "Epoch 2: val_loss improved from 0.03098 to 0.02873, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 157s 19ms/step - loss: 0.0455 - accuracy: 0.9315 - val_loss: 0.0287 - val_accuracy: 0.9437\n",
      "Epoch 3/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9315\n",
      "Epoch 3: val_loss did not improve from 0.02873\n",
      "8164/8164 [==============================] - 149s 18ms/step - loss: 0.0442 - accuracy: 0.9315 - val_loss: 0.0297 - val_accuracy: 0.9437\n",
      "Epoch 4/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9315\n",
      "Epoch 4: val_loss improved from 0.02873 to 0.02815, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 151s 19ms/step - loss: 0.0437 - accuracy: 0.9315 - val_loss: 0.0282 - val_accuracy: 0.9437\n",
      "Epoch 5/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9315\n",
      "Epoch 5: val_loss improved from 0.02815 to 0.02815, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 151s 19ms/step - loss: 0.0438 - accuracy: 0.9315 - val_loss: 0.0281 - val_accuracy: 0.9437\n",
      "Epoch 6/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9315\n",
      "Epoch 6: val_loss improved from 0.02815 to 0.02798, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 156s 19ms/step - loss: 0.0437 - accuracy: 0.9315 - val_loss: 0.0280 - val_accuracy: 0.9437\n",
      "Epoch 7/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9315\n",
      "Epoch 7: val_loss did not improve from 0.02798\n",
      "8164/8164 [==============================] - 155s 19ms/step - loss: 0.0436 - accuracy: 0.9315 - val_loss: 0.0283 - val_accuracy: 0.9437\n",
      "Epoch 8/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9315\n",
      "Epoch 8: val_loss improved from 0.02798 to 0.02768, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 155s 19ms/step - loss: 0.0435 - accuracy: 0.9315 - val_loss: 0.0277 - val_accuracy: 0.9437\n",
      "Epoch 9/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9315\n",
      "Epoch 9: val_loss did not improve from 0.02768\n",
      "8164/8164 [==============================] - 158s 19ms/step - loss: 0.0436 - accuracy: 0.9315 - val_loss: 0.0278 - val_accuracy: 0.9437\n",
      "Epoch 10/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9315\n",
      "Epoch 10: val_loss did not improve from 0.02768\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0436 - accuracy: 0.9315 - val_loss: 0.0283 - val_accuracy: 0.9437\n",
      "Epoch 11/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9315\n",
      "Epoch 11: val_loss improved from 0.02768 to 0.02760, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 153s 19ms/step - loss: 0.0434 - accuracy: 0.9315 - val_loss: 0.0276 - val_accuracy: 0.9437\n",
      "Epoch 12/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9315\n",
      "Epoch 12: val_loss improved from 0.02760 to 0.02739, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 152s 19ms/step - loss: 0.0432 - accuracy: 0.9315 - val_loss: 0.0274 - val_accuracy: 0.9437\n",
      "Epoch 13/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9315\n",
      "Epoch 13: val_loss did not improve from 0.02739\n",
      "8164/8164 [==============================] - 152s 19ms/step - loss: 0.0431 - accuracy: 0.9315 - val_loss: 0.0277 - val_accuracy: 0.9437\n",
      "Epoch 14/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9315\n",
      "Epoch 14: val_loss did not improve from 0.02739\n",
      "8164/8164 [==============================] - 152s 19ms/step - loss: 0.0432 - accuracy: 0.9315 - val_loss: 0.0283 - val_accuracy: 0.9437\n",
      "Epoch 15/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9315\n",
      "Epoch 15: val_loss did not improve from 0.02739\n",
      "8164/8164 [==============================] - 152s 19ms/step - loss: 0.0434 - accuracy: 0.9315 - val_loss: 0.0281 - val_accuracy: 0.9437\n",
      "Epoch 16/100\n",
      "8164/8164 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9315\n",
      "Epoch 16: val_loss did not improve from 0.02739\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0433 - accuracy: 0.9315 - val_loss: 0.0280 - val_accuracy: 0.9437\n",
      "Epoch 17/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9315\n",
      "Epoch 17: val_loss improved from 0.02739 to 0.02737, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 152s 19ms/step - loss: 0.0435 - accuracy: 0.9315 - val_loss: 0.0274 - val_accuracy: 0.9437\n",
      "Epoch 18/100\n",
      "8161/8164 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9315\n",
      "Epoch 18: val_loss did not improve from 0.02737\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0433 - accuracy: 0.9315 - val_loss: 0.0276 - val_accuracy: 0.9437\n",
      "Epoch 19/100\n",
      "8161/8164 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9315\n",
      "Epoch 19: val_loss did not improve from 0.02737\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0431 - accuracy: 0.9315 - val_loss: 0.0283 - val_accuracy: 0.9437\n",
      "Epoch 20/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9315\n",
      "Epoch 20: val_loss improved from 0.02737 to 0.02718, saving model to ./model_transformer2\\best_model_2_09.h5\n",
      "8164/8164 [==============================] - 153s 19ms/step - loss: 0.0432 - accuracy: 0.9315 - val_loss: 0.0272 - val_accuracy: 0.9437\n",
      "Epoch 21/100\n",
      "8161/8164 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9315\n",
      "Epoch 21: val_loss did not improve from 0.02718\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0435 - accuracy: 0.9315 - val_loss: 0.0272 - val_accuracy: 0.9437\n",
      "Epoch 22/100\n",
      "8163/8164 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9315\n",
      "Epoch 22: val_loss did not improve from 0.02718\n",
      "8164/8164 [==============================] - 154s 19ms/step - loss: 0.0432 - accuracy: 0.9315 - val_loss: 0.0278 - val_accuracy: 0.9437\n",
      "Epoch 23/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9315\n",
      "Epoch 23: val_loss did not improve from 0.02718\n",
      "8164/8164 [==============================] - 153s 19ms/step - loss: 0.0432 - accuracy: 0.9315 - val_loss: 0.0276 - val_accuracy: 0.9437\n",
      "Epoch 24/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9315\n",
      "Epoch 24: val_loss did not improve from 0.02718\n",
      "8164/8164 [==============================] - 158s 19ms/step - loss: 0.0429 - accuracy: 0.9315 - val_loss: 0.0278 - val_accuracy: 0.9437\n",
      "Epoch 25/100\n",
      "8162/8164 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9315\n",
      "Epoch 25: val_loss did not improve from 0.02718\n",
      "8164/8164 [==============================] - 156s 19ms/step - loss: 0.0436 - accuracy: 0.9315 - val_loss: 0.0283 - val_accuracy: 0.9437\n",
      "Epoch 26/100\n",
      "1388/8164 [====>.........................] - ETA: 2:04 - loss: 0.0459 - accuracy: 0.9279"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 8s 9ms/step - loss: 0.0950 - accuracy: 0.7201\n",
      "Test Accuracy: 0.7201\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 6s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3907\n",
      "           1       0.72      1.00      0.84     20157\n",
      "           2       0.00      0.00      0.00      3927\n",
      "\n",
      "    accuracy                           0.72     27991\n",
      "   macro avg       0.24      0.33      0.28     27991\n",
      "weighted avg       0.52      0.72      0.60     27991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 자세한 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 혼동 행렬 계산 및 시각화\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 정확도 시각화\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도 시각화\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 손실 시각화\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
