{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 400분 단위로 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149150, 400, 3)\n",
      "(149150,)\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 전처리\n",
    "def create_classification_targets(data, window_size=400, pred_offset=3):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - window_size - pred_offset + 1):\n",
    "        sequence = data.iloc[i:i+window_size]\n",
    "        scaled_sequence = scale_within_sequence(sequence)\n",
    "        X.append(scaled_sequence)\n",
    "        # 3분 뒤의 Close 가격 변화에 따른 클래스 설정\n",
    "        future_close = data.iloc[i+window_size+pred_offset-1]['Close']\n",
    "        current_close = data.iloc[i+window_size-1]['Close']\n",
    "        \n",
    "        # 가격 변화에 따라 클래스 설정: 상승(2), 보합(1), 하락(0)\n",
    "        if future_close > current_close:\n",
    "            y.append(2)  # 상승\n",
    "        elif future_close < current_close:\n",
    "            y.append(0)  # 하락\n",
    "        else:\n",
    "            y.append(1)  # 보합\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 데이터 불러오기 및 전처리\n",
    "data = pd.read_csv('./000660.csv', parse_dates=['Unnamed: 0'])\n",
    "data = data.rename(columns={'Unnamed: 0': 'Time', '매수량': 'BuyVolume', '매도량': 'SellVolume', '종가': 'Close', '저가': 'Low'})\n",
    "data['Power'] = data['BuyVolume'] - data['SellVolume']\n",
    "columns = ['Close', 'Power', 'Low']\n",
    "data = data[columns].dropna()\n",
    "\n",
    "# 데이터 정규화\n",
    "# Power 전체 스케일\n",
    "volume_scaler = RobustScaler()\n",
    "data['Scaled_Power'] = volume_scaler.fit_transform(data[['Power']])\n",
    "\n",
    "# 시퀀스내 스케일 종가, 저가\n",
    "def scale_within_sequence(sequence):\n",
    "    # 종가 스케일 시퀀스내\n",
    "    close_scaler = RobustScaler()\n",
    "    close_scaled = close_scaler.fit_transform(sequence[['Close']].values)\n",
    "    \n",
    "    # 저가 스케일 시퀀스내\n",
    "    low_scaled = close_scaler.transform(sequence[['Low']].values)\n",
    "    \n",
    "    # 거래량 미리 스케일값 사용\n",
    "    power_scaled = sequence[['Scaled_Power']].values\n",
    "    \n",
    "    return np.hstack([close_scaled, low_scaled, power_scaled])\n",
    "\n",
    "\n",
    "X, y = create_classification_targets(data)\n",
    "\n",
    "# 학습/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)  # (samples, 10, 3)\n",
    "print(y_train.shape)  # (samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52596 45490 51064]\n"
     ]
    }
   ],
   "source": [
    "# y 클래스 데이터 분포 확인\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Positional Encoding 구현\n",
    "def positional_encoding(max_len, d_model):\n",
    "    pos = np.arange(max_len)[:, np.newaxis]\n",
    "    i = np.arange(d_model)[np.newaxis, :]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    angle_rads = pos * angle_rates\n",
    "\n",
    "    # 짝수 인덱스에 대해 sin 적용\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 홀수 인덱스에 대해 cos 적용\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "    return pos_encoding\n",
    "\n",
    "def add_positional_encoding(inputs, max_len, d_model):\n",
    "    pos_encoding = positional_encoding(max_len, d_model)\n",
    "    pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    pos_encoded_inputs = inputs + pos_encoding[:tf.shape(inputs)[1], :]\n",
    "    return pos_encoded_inputs\n",
    "\n",
    "# 3. Transformer 블록 구현\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"gelu\", kernel_initializer='he_normal'), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output1 = self.att1(inputs, inputs)\n",
    "        attn_output1 = self.dropout1(attn_output1)\n",
    "        out1 = self.layernorm1(inputs + attn_output1)\n",
    "        # attn_output2 = self.att2(out1, out1)\n",
    "        # attn_output2 = self.dropout2(attn_output2)\n",
    "        # out2 = self.layernorm1(out1 + attn_output2)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout1(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 4. Transformer 모델 구성\n",
    "def create_transformer_model(input_shape, num_heads, ff_dim, d_model, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 임베딩 및 위치 인코딩\n",
    "    embedding_layer = layers.Dense(d_model, kernel_initializer='he_normal')(inputs)\n",
    "    pos_encoded_inputs = add_positional_encoding(embedding_layer, max_len=input_shape[0], d_model=d_model)\n",
    "\n",
    "    # Transformer 블록 적용\n",
    "    transformer_block = TransformerBlock(d_model, num_heads, ff_dim)\n",
    "    x = transformer_block(pos_encoded_inputs)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"gelu\", kernel_initializer='he_normal')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Positional Encoding 구현\n",
    "def positional_encoding(max_len, d_model):\n",
    "    pos = np.arange(max_len)[:, np.newaxis]\n",
    "    i = np.arange(d_model)[np.newaxis, :]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    angle_rads = pos * angle_rates\n",
    "\n",
    "    # 짝수 인덱스에 대해 sin 적용\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 홀수 인덱스에 대해 cos 적용\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "    return pos_encoding\n",
    "\n",
    "def add_positional_encoding(inputs, max_len, d_model):\n",
    "    pos_encoding = positional_encoding(max_len, d_model)\n",
    "    pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    pos_encoded_inputs = inputs + pos_encoding[:tf.shape(inputs)[1], :]\n",
    "    return pos_encoded_inputs\n",
    "\n",
    "# 3. Transformer 블록 구현\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"gelu\", kernel_initializer='he_normal'), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output1 = self.att1(inputs, inputs)\n",
    "        attn_output1 = self.dropout1(attn_output1)\n",
    "        out1 = self.layernorm1(inputs + attn_output1)\n",
    "        # attn_output2 = self.att2(out1, out1)\n",
    "        # attn_output2 = self.dropout2(attn_output2)\n",
    "        # out2 = self.layernorm1(out1 + attn_output2)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout1(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 4. Transformer 모델 구성\n",
    "def create_transformer_model(input_shape, num_heads, ff_dim, d_model, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 임베딩 및 위치 인코딩\n",
    "    embedding_layer = layers.Dense(d_model, kernel_initializer='he_normal')(inputs)\n",
    "    pos_encoded_inputs = add_positional_encoding(embedding_layer, max_len=input_shape[0], d_model=d_model)\n",
    "\n",
    "    # Transformer 블록 적용\n",
    "    transformer_block = TransformerBlock(d_model, num_heads, ff_dim)\n",
    "    x = transformer_block(pos_encoded_inputs)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"gelu\", kernel_initializer='he_normal')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_5.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.8, \n",
    "    patience=50, \n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 400, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 400, 128)     512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['dense[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.stack (TFOpLambda)          (2,)                 0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.strided_slice (TFOpLambda)  (400, 128)           0           ['tf.stack[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 400, 128)    0           ['dense[0][0]',                  \n",
      " da)                                                              'tf.strided_slice[0][0]']       \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 400, 128)    297344      ['tf.__operators__.add[0][0]']   \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['transformer_block[0][0]']      \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 3)            387         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 314,755\n",
      "Trainable params: 314,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0914 - accuracy: 0.3693\n",
      "Epoch 1: val_loss improved from inf to 1.08604, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 203s 172ms/step - loss: 1.0914 - accuracy: 0.3692 - val_loss: 1.0860 - val_accuracy: 0.3756 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0856 - accuracy: 0.3759\n",
      "Epoch 2: val_loss did not improve from 1.08604\n",
      "1166/1166 [==============================] - 193s 165ms/step - loss: 1.0856 - accuracy: 0.3759 - val_loss: 1.0883 - val_accuracy: 0.3721 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0845 - accuracy: 0.3774\n",
      "Epoch 3: val_loss did not improve from 1.08604\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0845 - accuracy: 0.3774 - val_loss: 1.0870 - val_accuracy: 0.3741 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.3787\n",
      "Epoch 4: val_loss improved from 1.08604 to 1.08535, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0838 - accuracy: 0.3787 - val_loss: 1.0853 - val_accuracy: 0.3795 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0837 - accuracy: 0.3785\n",
      "Epoch 5: val_loss improved from 1.08535 to 1.08215, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0837 - accuracy: 0.3784 - val_loss: 1.0822 - val_accuracy: 0.3749 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0827 - accuracy: 0.3788\n",
      "Epoch 6: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0827 - accuracy: 0.3788 - val_loss: 1.0827 - val_accuracy: 0.3799 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0825 - accuracy: 0.3789\n",
      "Epoch 7: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0825 - accuracy: 0.3789 - val_loss: 1.0863 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0827 - accuracy: 0.3796\n",
      "Epoch 8: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0827 - accuracy: 0.3796 - val_loss: 1.0846 - val_accuracy: 0.3788 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0821 - accuracy: 0.3786\n",
      "Epoch 9: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0821 - accuracy: 0.3786 - val_loss: 1.0894 - val_accuracy: 0.3686 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0834 - accuracy: 0.3784\n",
      "Epoch 10: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0834 - accuracy: 0.3784 - val_loss: 1.0869 - val_accuracy: 0.3725 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0832 - accuracy: 0.3792\n",
      "Epoch 11: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0832 - accuracy: 0.3792 - val_loss: 1.0828 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0828 - accuracy: 0.3794\n",
      "Epoch 12: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0828 - accuracy: 0.3794 - val_loss: 1.0845 - val_accuracy: 0.3793 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0814 - accuracy: 0.3808\n",
      "Epoch 13: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0814 - accuracy: 0.3808 - val_loss: 1.0882 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0811 - accuracy: 0.3824\n",
      "Epoch 14: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0811 - accuracy: 0.3824 - val_loss: 1.0848 - val_accuracy: 0.3731 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0808 - accuracy: 0.3819\n",
      "Epoch 15: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0808 - accuracy: 0.3819 - val_loss: 1.0856 - val_accuracy: 0.3759 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0803 - accuracy: 0.3827\n",
      "Epoch 16: val_loss did not improve from 1.08215\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0803 - accuracy: 0.3827 - val_loss: 1.0873 - val_accuracy: 0.3692 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0804 - accuracy: 0.3831\n",
      "Epoch 17: val_loss improved from 1.08215 to 1.08076, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0804 - accuracy: 0.3831 - val_loss: 1.0808 - val_accuracy: 0.3823 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0797 - accuracy: 0.3833\n",
      "Epoch 18: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0797 - accuracy: 0.3833 - val_loss: 1.0838 - val_accuracy: 0.3744 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0798 - accuracy: 0.3824\n",
      "Epoch 19: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0798 - accuracy: 0.3824 - val_loss: 1.0834 - val_accuracy: 0.3771 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0796 - accuracy: 0.3820\n",
      "Epoch 20: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0796 - accuracy: 0.3820 - val_loss: 1.0848 - val_accuracy: 0.3766 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0798 - accuracy: 0.3824\n",
      "Epoch 21: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0798 - accuracy: 0.3824 - val_loss: 1.0841 - val_accuracy: 0.3763 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0797 - accuracy: 0.3836\n",
      "Epoch 22: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0797 - accuracy: 0.3836 - val_loss: 1.0829 - val_accuracy: 0.3782 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0791 - accuracy: 0.3845\n",
      "Epoch 23: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0791 - accuracy: 0.3845 - val_loss: 1.0808 - val_accuracy: 0.3802 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0791 - accuracy: 0.3843\n",
      "Epoch 24: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0791 - accuracy: 0.3843 - val_loss: 1.0886 - val_accuracy: 0.3707 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0789 - accuracy: 0.3835\n",
      "Epoch 25: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0789 - accuracy: 0.3835 - val_loss: 1.0834 - val_accuracy: 0.3747 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0786 - accuracy: 0.3841\n",
      "Epoch 26: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0786 - accuracy: 0.3841 - val_loss: 1.0828 - val_accuracy: 0.3789 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0781 - accuracy: 0.3841\n",
      "Epoch 27: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0781 - accuracy: 0.3841 - val_loss: 1.0855 - val_accuracy: 0.3795 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0785 - accuracy: 0.3857\n",
      "Epoch 28: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0785 - accuracy: 0.3857 - val_loss: 1.0822 - val_accuracy: 0.3791 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0782 - accuracy: 0.3859\n",
      "Epoch 29: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0782 - accuracy: 0.3859 - val_loss: 1.0811 - val_accuracy: 0.3821 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.3869\n",
      "Epoch 30: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0777 - accuracy: 0.3869 - val_loss: 1.0828 - val_accuracy: 0.3795 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0782 - accuracy: 0.3852\n",
      "Epoch 31: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0782 - accuracy: 0.3852 - val_loss: 1.0813 - val_accuracy: 0.3828 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.3861\n",
      "Epoch 32: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0779 - accuracy: 0.3860 - val_loss: 1.0942 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.3872\n",
      "Epoch 33: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0779 - accuracy: 0.3872 - val_loss: 1.0820 - val_accuracy: 0.3783 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0778 - accuracy: 0.3845\n",
      "Epoch 34: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0778 - accuracy: 0.3845 - val_loss: 1.0835 - val_accuracy: 0.3780 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0777 - accuracy: 0.3864\n",
      "Epoch 35: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0777 - accuracy: 0.3864 - val_loss: 1.0822 - val_accuracy: 0.3799 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0775 - accuracy: 0.3870\n",
      "Epoch 36: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0775 - accuracy: 0.3870 - val_loss: 1.0836 - val_accuracy: 0.3791 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0774 - accuracy: 0.3874\n",
      "Epoch 37: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0774 - accuracy: 0.3874 - val_loss: 1.0868 - val_accuracy: 0.3734 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.3870\n",
      "Epoch 38: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0773 - accuracy: 0.3870 - val_loss: 1.0834 - val_accuracy: 0.3792 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.3882\n",
      "Epoch 39: val_loss did not improve from 1.08076\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0773 - accuracy: 0.3882 - val_loss: 1.0809 - val_accuracy: 0.3783 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.3890\n",
      "Epoch 40: val_loss improved from 1.08076 to 1.07982, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0773 - accuracy: 0.3890 - val_loss: 1.0798 - val_accuracy: 0.3845 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0768 - accuracy: 0.3873\n",
      "Epoch 41: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0768 - accuracy: 0.3873 - val_loss: 1.0845 - val_accuracy: 0.3804 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0772 - accuracy: 0.3886\n",
      "Epoch 42: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0772 - accuracy: 0.3886 - val_loss: 1.0806 - val_accuracy: 0.3821 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0765 - accuracy: 0.3884\n",
      "Epoch 43: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0765 - accuracy: 0.3884 - val_loss: 1.0872 - val_accuracy: 0.3728 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0760 - accuracy: 0.3884\n",
      "Epoch 44: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0760 - accuracy: 0.3884 - val_loss: 1.0827 - val_accuracy: 0.3772 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0765 - accuracy: 0.3880\n",
      "Epoch 45: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0766 - accuracy: 0.3880 - val_loss: 1.0815 - val_accuracy: 0.3798 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0766 - accuracy: 0.3877\n",
      "Epoch 46: val_loss did not improve from 1.07982\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0766 - accuracy: 0.3877 - val_loss: 1.0800 - val_accuracy: 0.3830 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0763 - accuracy: 0.3881\n",
      "Epoch 47: val_loss improved from 1.07982 to 1.07946, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0763 - accuracy: 0.3881 - val_loss: 1.0795 - val_accuracy: 0.3832 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0762 - accuracy: 0.3895\n",
      "Epoch 48: val_loss did not improve from 1.07946\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0762 - accuracy: 0.3895 - val_loss: 1.0875 - val_accuracy: 0.3745 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0758 - accuracy: 0.3885\n",
      "Epoch 49: val_loss did not improve from 1.07946\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0758 - accuracy: 0.3885 - val_loss: 1.0800 - val_accuracy: 0.3830 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0758 - accuracy: 0.3892\n",
      "Epoch 50: val_loss did not improve from 1.07946\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0758 - accuracy: 0.3892 - val_loss: 1.0833 - val_accuracy: 0.3806 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0759 - accuracy: 0.3902\n",
      "Epoch 51: val_loss improved from 1.07946 to 1.07828, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0759 - accuracy: 0.3902 - val_loss: 1.0783 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0759 - accuracy: 0.3894\n",
      "Epoch 52: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0759 - accuracy: 0.3894 - val_loss: 1.0809 - val_accuracy: 0.3846 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0762 - accuracy: 0.3878\n",
      "Epoch 53: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0762 - accuracy: 0.3878 - val_loss: 1.0794 - val_accuracy: 0.3836 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0757 - accuracy: 0.3898\n",
      "Epoch 54: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0757 - accuracy: 0.3898 - val_loss: 1.0799 - val_accuracy: 0.3823 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0759 - accuracy: 0.3892\n",
      "Epoch 55: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0760 - accuracy: 0.3892 - val_loss: 1.0794 - val_accuracy: 0.3826 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0758 - accuracy: 0.3900\n",
      "Epoch 56: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0758 - accuracy: 0.3901 - val_loss: 1.0807 - val_accuracy: 0.3826 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0755 - accuracy: 0.3902\n",
      "Epoch 57: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0755 - accuracy: 0.3902 - val_loss: 1.0817 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0757 - accuracy: 0.3895\n",
      "Epoch 58: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0757 - accuracy: 0.3895 - val_loss: 1.0814 - val_accuracy: 0.3802 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0752 - accuracy: 0.3905\n",
      "Epoch 59: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0752 - accuracy: 0.3905 - val_loss: 1.0807 - val_accuracy: 0.3801 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0753 - accuracy: 0.3909\n",
      "Epoch 60: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0753 - accuracy: 0.3909 - val_loss: 1.0852 - val_accuracy: 0.3768 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0751 - accuracy: 0.3898\n",
      "Epoch 61: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0751 - accuracy: 0.3898 - val_loss: 1.0809 - val_accuracy: 0.3841 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0758 - accuracy: 0.3890\n",
      "Epoch 62: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0758 - accuracy: 0.3890 - val_loss: 1.0820 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0753 - accuracy: 0.3916\n",
      "Epoch 63: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0753 - accuracy: 0.3916 - val_loss: 1.0798 - val_accuracy: 0.3833 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0755 - accuracy: 0.3892\n",
      "Epoch 64: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0755 - accuracy: 0.3892 - val_loss: 1.0799 - val_accuracy: 0.3829 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0754 - accuracy: 0.3905\n",
      "Epoch 65: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0754 - accuracy: 0.3905 - val_loss: 1.0786 - val_accuracy: 0.3860 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0747 - accuracy: 0.3919\n",
      "Epoch 66: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3919 - val_loss: 1.0797 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0752 - accuracy: 0.3918\n",
      "Epoch 67: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0752 - accuracy: 0.3918 - val_loss: 1.0808 - val_accuracy: 0.3841 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0750 - accuracy: 0.3916\n",
      "Epoch 68: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0750 - accuracy: 0.3916 - val_loss: 1.0828 - val_accuracy: 0.3848 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0754 - accuracy: 0.3919\n",
      "Epoch 69: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0754 - accuracy: 0.3919 - val_loss: 1.0802 - val_accuracy: 0.3835 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0753 - accuracy: 0.3920\n",
      "Epoch 70: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0753 - accuracy: 0.3920 - val_loss: 1.0814 - val_accuracy: 0.3855 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0750 - accuracy: 0.3932\n",
      "Epoch 71: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0750 - accuracy: 0.3932 - val_loss: 1.0793 - val_accuracy: 0.3844 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0752 - accuracy: 0.3923\n",
      "Epoch 72: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0752 - accuracy: 0.3923 - val_loss: 1.0852 - val_accuracy: 0.3800 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0748 - accuracy: 0.3928\n",
      "Epoch 73: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0748 - accuracy: 0.3928 - val_loss: 1.0792 - val_accuracy: 0.3867 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0747 - accuracy: 0.3926\n",
      "Epoch 74: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3926 - val_loss: 1.0783 - val_accuracy: 0.3841 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0749 - accuracy: 0.3931\n",
      "Epoch 75: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0749 - accuracy: 0.3931 - val_loss: 1.0825 - val_accuracy: 0.3822 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0748 - accuracy: 0.3945\n",
      "Epoch 76: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3946 - val_loss: 1.0835 - val_accuracy: 0.3803 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0749 - accuracy: 0.3935\n",
      "Epoch 77: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0749 - accuracy: 0.3935 - val_loss: 1.0820 - val_accuracy: 0.3833 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0748 - accuracy: 0.3936\n",
      "Epoch 78: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0748 - accuracy: 0.3936 - val_loss: 1.0799 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0748 - accuracy: 0.3936\n",
      "Epoch 79: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0748 - accuracy: 0.3936 - val_loss: 1.0833 - val_accuracy: 0.3821 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.3929\n",
      "Epoch 80: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3929 - val_loss: 1.0905 - val_accuracy: 0.3749 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0746 - accuracy: 0.3935\n",
      "Epoch 81: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0746 - accuracy: 0.3934 - val_loss: 1.0784 - val_accuracy: 0.3877 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0744 - accuracy: 0.3939\n",
      "Epoch 82: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0744 - accuracy: 0.3939 - val_loss: 1.0792 - val_accuracy: 0.3883 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0748 - accuracy: 0.3929\n",
      "Epoch 83: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0748 - accuracy: 0.3929 - val_loss: 1.0808 - val_accuracy: 0.3844 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0748 - accuracy: 0.3944\n",
      "Epoch 84: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0748 - accuracy: 0.3944 - val_loss: 1.0839 - val_accuracy: 0.3819 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0747 - accuracy: 0.3943\n",
      "Epoch 85: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3943 - val_loss: 1.0790 - val_accuracy: 0.3836 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0744 - accuracy: 0.3936\n",
      "Epoch 86: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0744 - accuracy: 0.3936 - val_loss: 1.0798 - val_accuracy: 0.3826 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0745 - accuracy: 0.3937\n",
      "Epoch 87: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0745 - accuracy: 0.3937 - val_loss: 1.0896 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.3942\n",
      "Epoch 88: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3942 - val_loss: 1.0809 - val_accuracy: 0.3823 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0744 - accuracy: 0.3940\n",
      "Epoch 89: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0744 - accuracy: 0.3939 - val_loss: 1.0803 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0749 - accuracy: 0.3921\n",
      "Epoch 90: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0749 - accuracy: 0.3921 - val_loss: 1.0830 - val_accuracy: 0.3816 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0747 - accuracy: 0.3942\n",
      "Epoch 91: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0747 - accuracy: 0.3942 - val_loss: 1.0797 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0746 - accuracy: 0.3942\n",
      "Epoch 92: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0746 - accuracy: 0.3942 - val_loss: 1.0800 - val_accuracy: 0.3848 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.3933\n",
      "Epoch 93: val_loss did not improve from 1.07828\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0745 - accuracy: 0.3933 - val_loss: 1.0790 - val_accuracy: 0.3877 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0742 - accuracy: 0.3950\n",
      "Epoch 94: val_loss improved from 1.07828 to 1.07798, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0742 - accuracy: 0.3950 - val_loss: 1.0780 - val_accuracy: 0.3895 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.3931\n",
      "Epoch 95: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0743 - accuracy: 0.3931 - val_loss: 1.0808 - val_accuracy: 0.3810 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0741 - accuracy: 0.3961\n",
      "Epoch 96: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0741 - accuracy: 0.3961 - val_loss: 1.0802 - val_accuracy: 0.3867 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.3950\n",
      "Epoch 97: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0743 - accuracy: 0.3950 - val_loss: 1.0818 - val_accuracy: 0.3833 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0742 - accuracy: 0.3948\n",
      "Epoch 98: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0743 - accuracy: 0.3948 - val_loss: 1.0853 - val_accuracy: 0.3782 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0740 - accuracy: 0.3958\n",
      "Epoch 99: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0739 - accuracy: 0.3958 - val_loss: 1.0796 - val_accuracy: 0.3883 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.3945\n",
      "Epoch 100: val_loss did not improve from 1.07798\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0745 - accuracy: 0.3945 - val_loss: 1.0799 - val_accuracy: 0.3868 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0743 - accuracy: 0.3950\n",
      "Epoch 101: val_loss improved from 1.07798 to 1.07671, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0743 - accuracy: 0.3950 - val_loss: 1.0767 - val_accuracy: 0.3961 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0646 - accuracy: 0.4151\n",
      "Epoch 102: val_loss improved from 1.07671 to 1.06157, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0646 - accuracy: 0.4151 - val_loss: 1.0616 - val_accuracy: 0.4155 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0572 - accuracy: 0.4243\n",
      "Epoch 103: val_loss improved from 1.06157 to 1.05684, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0572 - accuracy: 0.4243 - val_loss: 1.0568 - val_accuracy: 0.4186 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0528 - accuracy: 0.4295\n",
      "Epoch 104: val_loss improved from 1.05684 to 1.05568, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0528 - accuracy: 0.4295 - val_loss: 1.0557 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0509 - accuracy: 0.4324\n",
      "Epoch 105: val_loss improved from 1.05568 to 1.05443, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0509 - accuracy: 0.4324 - val_loss: 1.0544 - val_accuracy: 0.4304 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0499 - accuracy: 0.4310\n",
      "Epoch 106: val_loss improved from 1.05443 to 1.05296, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0499 - accuracy: 0.4310 - val_loss: 1.0530 - val_accuracy: 0.4315 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0484 - accuracy: 0.4338\n",
      "Epoch 107: val_loss improved from 1.05296 to 1.04908, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0484 - accuracy: 0.4338 - val_loss: 1.0491 - val_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0480 - accuracy: 0.4354\n",
      "Epoch 108: val_loss did not improve from 1.04908\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0480 - accuracy: 0.4354 - val_loss: 1.0608 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0471 - accuracy: 0.4357\n",
      "Epoch 109: val_loss did not improve from 1.04908\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0471 - accuracy: 0.4357 - val_loss: 1.0545 - val_accuracy: 0.4291 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0468 - accuracy: 0.4364\n",
      "Epoch 110: val_loss did not improve from 1.04908\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0468 - accuracy: 0.4364 - val_loss: 1.0514 - val_accuracy: 0.4252 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0458 - accuracy: 0.4386\n",
      "Epoch 111: val_loss improved from 1.04908 to 1.04897, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0458 - accuracy: 0.4386 - val_loss: 1.0490 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0456 - accuracy: 0.4375\n",
      "Epoch 112: val_loss improved from 1.04897 to 1.04531, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0456 - accuracy: 0.4375 - val_loss: 1.0453 - val_accuracy: 0.4379 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0453 - accuracy: 0.4383\n",
      "Epoch 113: val_loss did not improve from 1.04531\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0453 - accuracy: 0.4383 - val_loss: 1.0520 - val_accuracy: 0.4277 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0456 - accuracy: 0.4371\n",
      "Epoch 114: val_loss did not improve from 1.04531\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0456 - accuracy: 0.4371 - val_loss: 1.0531 - val_accuracy: 0.4305 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0449 - accuracy: 0.4372\n",
      "Epoch 115: val_loss improved from 1.04531 to 1.04456, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0449 - accuracy: 0.4373 - val_loss: 1.0446 - val_accuracy: 0.4345 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0445 - accuracy: 0.4378\n",
      "Epoch 116: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0445 - accuracy: 0.4378 - val_loss: 1.0743 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0446 - accuracy: 0.4387\n",
      "Epoch 117: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0446 - accuracy: 0.4387 - val_loss: 1.0488 - val_accuracy: 0.4333 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0441 - accuracy: 0.4381\n",
      "Epoch 118: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0441 - accuracy: 0.4381 - val_loss: 1.0500 - val_accuracy: 0.4348 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0436 - accuracy: 0.4374\n",
      "Epoch 119: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0436 - accuracy: 0.4374 - val_loss: 1.0945 - val_accuracy: 0.4130 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0439 - accuracy: 0.4387\n",
      "Epoch 120: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0439 - accuracy: 0.4387 - val_loss: 1.0506 - val_accuracy: 0.4306 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0427 - accuracy: 0.4407\n",
      "Epoch 121: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0427 - accuracy: 0.4407 - val_loss: 1.0446 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0423 - accuracy: 0.4409\n",
      "Epoch 122: val_loss did not improve from 1.04456\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0423 - accuracy: 0.4409 - val_loss: 1.0534 - val_accuracy: 0.4316 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0415 - accuracy: 0.4424\n",
      "Epoch 123: val_loss improved from 1.04456 to 1.04111, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0414 - accuracy: 0.4425 - val_loss: 1.0411 - val_accuracy: 0.4428 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0407 - accuracy: 0.4431\n",
      "Epoch 124: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0407 - accuracy: 0.4431 - val_loss: 1.0437 - val_accuracy: 0.4393 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0410 - accuracy: 0.4435\n",
      "Epoch 125: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0410 - accuracy: 0.4435 - val_loss: 1.0471 - val_accuracy: 0.4298 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0409 - accuracy: 0.4427\n",
      "Epoch 126: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0409 - accuracy: 0.4426 - val_loss: 1.0419 - val_accuracy: 0.4370 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0399 - accuracy: 0.4456\n",
      "Epoch 127: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0399 - accuracy: 0.4456 - val_loss: 1.0445 - val_accuracy: 0.4382 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0397 - accuracy: 0.4445\n",
      "Epoch 128: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0397 - accuracy: 0.4445 - val_loss: 1.0467 - val_accuracy: 0.4343 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0398 - accuracy: 0.4446\n",
      "Epoch 129: val_loss did not improve from 1.04111\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0398 - accuracy: 0.4446 - val_loss: 1.0418 - val_accuracy: 0.4430 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0387 - accuracy: 0.4463\n",
      "Epoch 130: val_loss improved from 1.04111 to 1.03979, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0387 - accuracy: 0.4463 - val_loss: 1.0398 - val_accuracy: 0.4461 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0390 - accuracy: 0.4456\n",
      "Epoch 131: val_loss improved from 1.03979 to 1.03952, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0390 - accuracy: 0.4456 - val_loss: 1.0395 - val_accuracy: 0.4453 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0393 - accuracy: 0.4475\n",
      "Epoch 132: val_loss did not improve from 1.03952\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0393 - accuracy: 0.4475 - val_loss: 1.0405 - val_accuracy: 0.4460 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0392 - accuracy: 0.4473\n",
      "Epoch 133: val_loss did not improve from 1.03952\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0392 - accuracy: 0.4472 - val_loss: 1.0461 - val_accuracy: 0.4348 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.4466\n",
      "Epoch 134: val_loss did not improve from 1.03952\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0391 - accuracy: 0.4466 - val_loss: 1.0405 - val_accuracy: 0.4433 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0391 - accuracy: 0.4455\n",
      "Epoch 135: val_loss did not improve from 1.03952\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0391 - accuracy: 0.4455 - val_loss: 1.0422 - val_accuracy: 0.4406 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0390 - accuracy: 0.4456\n",
      "Epoch 136: val_loss did not improve from 1.03952\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0390 - accuracy: 0.4456 - val_loss: 1.0453 - val_accuracy: 0.4408 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0384 - accuracy: 0.4475\n",
      "Epoch 137: val_loss improved from 1.03952 to 1.03876, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0384 - accuracy: 0.4475 - val_loss: 1.0388 - val_accuracy: 0.4415 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0388 - accuracy: 0.4456\n",
      "Epoch 138: val_loss did not improve from 1.03876\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0388 - accuracy: 0.4456 - val_loss: 1.0440 - val_accuracy: 0.4381 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0384 - accuracy: 0.4463\n",
      "Epoch 139: val_loss did not improve from 1.03876\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0383 - accuracy: 0.4463 - val_loss: 1.0414 - val_accuracy: 0.4436 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0386 - accuracy: 0.4475\n",
      "Epoch 140: val_loss did not improve from 1.03876\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0386 - accuracy: 0.4475 - val_loss: 1.0512 - val_accuracy: 0.4295 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0385 - accuracy: 0.4468\n",
      "Epoch 141: val_loss did not improve from 1.03876\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0385 - accuracy: 0.4468 - val_loss: 1.0391 - val_accuracy: 0.4442 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0379 - accuracy: 0.4476\n",
      "Epoch 142: val_loss did not improve from 1.03876\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0380 - accuracy: 0.4476 - val_loss: 1.0431 - val_accuracy: 0.4403 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0378 - accuracy: 0.4475\n",
      "Epoch 143: val_loss improved from 1.03876 to 1.03726, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0378 - accuracy: 0.4475 - val_loss: 1.0373 - val_accuracy: 0.4489 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0376 - accuracy: 0.4472\n",
      "Epoch 144: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0376 - accuracy: 0.4472 - val_loss: 1.0674 - val_accuracy: 0.4186 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0382 - accuracy: 0.4472\n",
      "Epoch 145: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0382 - accuracy: 0.4472 - val_loss: 1.0379 - val_accuracy: 0.4502 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0378 - accuracy: 0.4472\n",
      "Epoch 146: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0378 - accuracy: 0.4472 - val_loss: 1.0390 - val_accuracy: 0.4447 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0374 - accuracy: 0.4482\n",
      "Epoch 147: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0374 - accuracy: 0.4482 - val_loss: 1.0426 - val_accuracy: 0.4420 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0377 - accuracy: 0.4480\n",
      "Epoch 148: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0377 - accuracy: 0.4480 - val_loss: 1.0382 - val_accuracy: 0.4481 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0373 - accuracy: 0.4479\n",
      "Epoch 149: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0373 - accuracy: 0.4479 - val_loss: 1.0431 - val_accuracy: 0.4451 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0362 - accuracy: 0.4505\n",
      "Epoch 150: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0362 - accuracy: 0.4505 - val_loss: 1.0447 - val_accuracy: 0.4418 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0379 - accuracy: 0.4495\n",
      "Epoch 151: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0379 - accuracy: 0.4494 - val_loss: 1.0378 - val_accuracy: 0.4450 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0368 - accuracy: 0.4486\n",
      "Epoch 152: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0368 - accuracy: 0.4486 - val_loss: 1.0508 - val_accuracy: 0.4322 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0361 - accuracy: 0.4490\n",
      "Epoch 153: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0361 - accuracy: 0.4490 - val_loss: 1.0443 - val_accuracy: 0.4415 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0368 - accuracy: 0.4494\n",
      "Epoch 154: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0368 - accuracy: 0.4494 - val_loss: 1.0408 - val_accuracy: 0.4420 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0365 - accuracy: 0.4492\n",
      "Epoch 155: val_loss did not improve from 1.03726\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0365 - accuracy: 0.4492 - val_loss: 1.0515 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0367 - accuracy: 0.4496\n",
      "Epoch 156: val_loss improved from 1.03726 to 1.03609, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0367 - accuracy: 0.4496 - val_loss: 1.0361 - val_accuracy: 0.4483 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0371 - accuracy: 0.4478\n",
      "Epoch 157: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0371 - accuracy: 0.4478 - val_loss: 1.0393 - val_accuracy: 0.4492 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0371 - accuracy: 0.4480\n",
      "Epoch 158: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0371 - accuracy: 0.4480 - val_loss: 1.0445 - val_accuracy: 0.4388 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0367 - accuracy: 0.4492\n",
      "Epoch 159: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0367 - accuracy: 0.4492 - val_loss: 1.0405 - val_accuracy: 0.4426 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0359 - accuracy: 0.4505\n",
      "Epoch 160: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0359 - accuracy: 0.4505 - val_loss: 1.0401 - val_accuracy: 0.4445 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0370 - accuracy: 0.4492\n",
      "Epoch 161: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0370 - accuracy: 0.4492 - val_loss: 1.0412 - val_accuracy: 0.4440 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0360 - accuracy: 0.4499\n",
      "Epoch 162: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0360 - accuracy: 0.4499 - val_loss: 1.0579 - val_accuracy: 0.4264 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0361 - accuracy: 0.4498\n",
      "Epoch 163: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0361 - accuracy: 0.4497 - val_loss: 1.0443 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.4499\n",
      "Epoch 164: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0353 - accuracy: 0.4499 - val_loss: 1.0385 - val_accuracy: 0.4462 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0360 - accuracy: 0.4508\n",
      "Epoch 165: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0360 - accuracy: 0.4508 - val_loss: 1.0406 - val_accuracy: 0.4424 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0357 - accuracy: 0.4495\n",
      "Epoch 166: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0357 - accuracy: 0.4495 - val_loss: 1.0389 - val_accuracy: 0.4430 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0351 - accuracy: 0.4522\n",
      "Epoch 167: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0351 - accuracy: 0.4522 - val_loss: 1.0422 - val_accuracy: 0.4402 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0354 - accuracy: 0.4495\n",
      "Epoch 168: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0354 - accuracy: 0.4495 - val_loss: 1.0418 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0359 - accuracy: 0.4515\n",
      "Epoch 169: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0359 - accuracy: 0.4515 - val_loss: 1.0380 - val_accuracy: 0.4453 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0357 - accuracy: 0.4501\n",
      "Epoch 170: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0357 - accuracy: 0.4500 - val_loss: 1.0436 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.4505\n",
      "Epoch 171: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4505 - val_loss: 1.0414 - val_accuracy: 0.4407 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4502\n",
      "Epoch 172: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4503 - val_loss: 1.0378 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.4504\n",
      "Epoch 173: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0354 - accuracy: 0.4504 - val_loss: 1.0366 - val_accuracy: 0.4448 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0357 - accuracy: 0.4505\n",
      "Epoch 174: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0357 - accuracy: 0.4505 - val_loss: 1.0390 - val_accuracy: 0.4451 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0364 - accuracy: 0.4496\n",
      "Epoch 175: val_loss did not improve from 1.03609\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0364 - accuracy: 0.4496 - val_loss: 1.0387 - val_accuracy: 0.4445 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4504\n",
      "Epoch 176: val_loss improved from 1.03609 to 1.03573, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4504 - val_loss: 1.0357 - val_accuracy: 0.4471 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.4505\n",
      "Epoch 177: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0350 - accuracy: 0.4505 - val_loss: 1.0430 - val_accuracy: 0.4396 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4518\n",
      "Epoch 178: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0347 - accuracy: 0.4518 - val_loss: 1.0384 - val_accuracy: 0.4456 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0356 - accuracy: 0.4501\n",
      "Epoch 179: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0356 - accuracy: 0.4501 - val_loss: 1.0383 - val_accuracy: 0.4445 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0358 - accuracy: 0.4517\n",
      "Epoch 180: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0358 - accuracy: 0.4517 - val_loss: 1.0450 - val_accuracy: 0.4383 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4509\n",
      "Epoch 181: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0349 - accuracy: 0.4509 - val_loss: 1.0380 - val_accuracy: 0.4453 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.4512\n",
      "Epoch 182: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0354 - accuracy: 0.4513 - val_loss: 1.0457 - val_accuracy: 0.4386 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.4509\n",
      "Epoch 183: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4509 - val_loss: 1.0401 - val_accuracy: 0.4480 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0352 - accuracy: 0.4511\n",
      "Epoch 184: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4511 - val_loss: 1.0403 - val_accuracy: 0.4445 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0355 - accuracy: 0.4510\n",
      "Epoch 185: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0355 - accuracy: 0.4510 - val_loss: 1.0516 - val_accuracy: 0.4373 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0350 - accuracy: 0.4501\n",
      "Epoch 186: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0351 - accuracy: 0.4501 - val_loss: 1.0490 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4514\n",
      "Epoch 187: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0350 - accuracy: 0.4514 - val_loss: 1.0595 - val_accuracy: 0.4215 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0351 - accuracy: 0.4495\n",
      "Epoch 188: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0351 - accuracy: 0.4495 - val_loss: 1.0397 - val_accuracy: 0.4429 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.4516\n",
      "Epoch 189: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0353 - accuracy: 0.4516 - val_loss: 1.0415 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4509\n",
      "Epoch 190: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0347 - accuracy: 0.4508 - val_loss: 1.0426 - val_accuracy: 0.4387 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0352 - accuracy: 0.4508\n",
      "Epoch 191: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4508 - val_loss: 1.0427 - val_accuracy: 0.4406 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.4519\n",
      "Epoch 192: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0353 - accuracy: 0.4519 - val_loss: 1.0523 - val_accuracy: 0.4374 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4503\n",
      "Epoch 193: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0347 - accuracy: 0.4503 - val_loss: 1.0444 - val_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4505\n",
      "Epoch 194: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4505 - val_loss: 1.0427 - val_accuracy: 0.4422 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4516\n",
      "Epoch 195: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4516 - val_loss: 1.0434 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4495\n",
      "Epoch 196: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4495 - val_loss: 1.0542 - val_accuracy: 0.4336 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0341 - accuracy: 0.4511\n",
      "Epoch 197: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0341 - accuracy: 0.4511 - val_loss: 1.0505 - val_accuracy: 0.4367 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4511\n",
      "Epoch 198: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0349 - accuracy: 0.4511 - val_loss: 1.0402 - val_accuracy: 0.4443 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4515\n",
      "Epoch 199: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4515 - val_loss: 1.0489 - val_accuracy: 0.4427 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4517\n",
      "Epoch 200: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0349 - accuracy: 0.4517 - val_loss: 1.0375 - val_accuracy: 0.4479 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4533\n",
      "Epoch 201: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4533 - val_loss: 1.0403 - val_accuracy: 0.4467 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4505\n",
      "Epoch 202: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0349 - accuracy: 0.4505 - val_loss: 1.0432 - val_accuracy: 0.4431 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.4510\n",
      "Epoch 203: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0346 - accuracy: 0.4510 - val_loss: 1.0635 - val_accuracy: 0.4334 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4522\n",
      "Epoch 204: val_loss did not improve from 1.03573\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0349 - accuracy: 0.4522 - val_loss: 1.0502 - val_accuracy: 0.4287 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0339 - accuracy: 0.4510\n",
      "Epoch 205: val_loss improved from 1.03573 to 1.03518, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4510 - val_loss: 1.0352 - val_accuracy: 0.4531 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4512\n",
      "Epoch 206: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0342 - accuracy: 0.4511 - val_loss: 1.0430 - val_accuracy: 0.4389 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4527\n",
      "Epoch 207: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4527 - val_loss: 1.0509 - val_accuracy: 0.4271 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4509\n",
      "Epoch 208: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4509 - val_loss: 1.0409 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4514\n",
      "Epoch 209: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0343 - accuracy: 0.4514 - val_loss: 1.0511 - val_accuracy: 0.4333 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.4513\n",
      "Epoch 210: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0346 - accuracy: 0.4513 - val_loss: 1.0485 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.4521\n",
      "Epoch 211: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0341 - accuracy: 0.4521 - val_loss: 1.0369 - val_accuracy: 0.4522 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4518\n",
      "Epoch 212: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4517 - val_loss: 1.0482 - val_accuracy: 0.4406 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4523\n",
      "Epoch 213: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4523 - val_loss: 1.0455 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.4511\n",
      "Epoch 214: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0350 - accuracy: 0.4511 - val_loss: 1.0516 - val_accuracy: 0.4317 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4516\n",
      "Epoch 215: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4517 - val_loss: 1.0431 - val_accuracy: 0.4404 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0343 - accuracy: 0.4507\n",
      "Epoch 216: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0343 - accuracy: 0.4507 - val_loss: 1.0446 - val_accuracy: 0.4337 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.4527\n",
      "Epoch 217: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0346 - accuracy: 0.4527 - val_loss: 1.0361 - val_accuracy: 0.4477 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4517\n",
      "Epoch 218: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0347 - accuracy: 0.4517 - val_loss: 1.0409 - val_accuracy: 0.4451 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4528\n",
      "Epoch 219: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0334 - accuracy: 0.4528 - val_loss: 1.0493 - val_accuracy: 0.4314 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0338 - accuracy: 0.4497\n",
      "Epoch 220: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0338 - accuracy: 0.4497 - val_loss: 1.0429 - val_accuracy: 0.4387 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4523\n",
      "Epoch 221: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0342 - accuracy: 0.4523 - val_loss: 1.0371 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0350 - accuracy: 0.4517\n",
      "Epoch 222: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0350 - accuracy: 0.4517 - val_loss: 1.0367 - val_accuracy: 0.4462 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.4524\n",
      "Epoch 223: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0341 - accuracy: 0.4524 - val_loss: 1.0498 - val_accuracy: 0.4337 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4507\n",
      "Epoch 224: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4507 - val_loss: 1.0384 - val_accuracy: 0.4453 - lr: 0.0010\n",
      "Epoch 225/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4514\n",
      "Epoch 225: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4514 - val_loss: 1.0495 - val_accuracy: 0.4335 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.4531\n",
      "Epoch 226: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4531 - val_loss: 1.0385 - val_accuracy: 0.4480 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0343 - accuracy: 0.4501\n",
      "Epoch 227: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0343 - accuracy: 0.4501 - val_loss: 1.0535 - val_accuracy: 0.4263 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4528\n",
      "Epoch 228: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0337 - accuracy: 0.4528 - val_loss: 1.0554 - val_accuracy: 0.4323 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4519\n",
      "Epoch 229: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0342 - accuracy: 0.4519 - val_loss: 1.0499 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.4493\n",
      "Epoch 230: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0353 - accuracy: 0.4493 - val_loss: 1.0521 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4524\n",
      "Epoch 231: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4524 - val_loss: 1.0432 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.4510\n",
      "Epoch 232: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0344 - accuracy: 0.4510 - val_loss: 1.0470 - val_accuracy: 0.4368 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4518\n",
      "Epoch 233: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4518 - val_loss: 1.0565 - val_accuracy: 0.4277 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0345 - accuracy: 0.4512\n",
      "Epoch 234: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4512 - val_loss: 1.0388 - val_accuracy: 0.4487 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4526\n",
      "Epoch 235: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0338 - accuracy: 0.4525 - val_loss: 1.0420 - val_accuracy: 0.4433 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4518\n",
      "Epoch 236: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4518 - val_loss: 1.0438 - val_accuracy: 0.4482 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4523\n",
      "Epoch 237: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4523 - val_loss: 1.0480 - val_accuracy: 0.4345 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4526\n",
      "Epoch 238: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0337 - accuracy: 0.4526 - val_loss: 1.0439 - val_accuracy: 0.4402 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0342 - accuracy: 0.4518\n",
      "Epoch 239: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0342 - accuracy: 0.4518 - val_loss: 1.0528 - val_accuracy: 0.4343 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4536\n",
      "Epoch 240: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4536 - val_loss: 1.0425 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0342 - accuracy: 0.4516\n",
      "Epoch 241: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0342 - accuracy: 0.4516 - val_loss: 1.0396 - val_accuracy: 0.4433 - lr: 0.0010\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0344 - accuracy: 0.4514\n",
      "Epoch 242: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0344 - accuracy: 0.4514 - val_loss: 1.0425 - val_accuracy: 0.4396 - lr: 0.0010\n",
      "Epoch 243/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4514\n",
      "Epoch 243: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0338 - accuracy: 0.4514 - val_loss: 1.0547 - val_accuracy: 0.4258 - lr: 0.0010\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0338 - accuracy: 0.4529\n",
      "Epoch 244: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0338 - accuracy: 0.4529 - val_loss: 1.0414 - val_accuracy: 0.4384 - lr: 0.0010\n",
      "Epoch 245/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4519\n",
      "Epoch 245: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0335 - accuracy: 0.4519 - val_loss: 1.0431 - val_accuracy: 0.4364 - lr: 0.0010\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0334 - accuracy: 0.4527\n",
      "Epoch 246: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0334 - accuracy: 0.4527 - val_loss: 1.0421 - val_accuracy: 0.4460 - lr: 0.0010\n",
      "Epoch 247/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4517\n",
      "Epoch 247: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4517 - val_loss: 1.0390 - val_accuracy: 0.4433 - lr: 0.0010\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.4524\n",
      "Epoch 248: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0332 - accuracy: 0.4524 - val_loss: 1.0415 - val_accuracy: 0.4391 - lr: 0.0010\n",
      "Epoch 249/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4507\n",
      "Epoch 249: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4507 - val_loss: 1.0429 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 250/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4528\n",
      "Epoch 250: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0334 - accuracy: 0.4528 - val_loss: 1.0418 - val_accuracy: 0.4479 - lr: 0.0010\n",
      "Epoch 251/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4527\n",
      "Epoch 251: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0335 - accuracy: 0.4527 - val_loss: 1.0553 - val_accuracy: 0.4317 - lr: 0.0010\n",
      "Epoch 252/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4520\n",
      "Epoch 252: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4520 - val_loss: 1.0439 - val_accuracy: 0.4379 - lr: 0.0010\n",
      "Epoch 253/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4515\n",
      "Epoch 253: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0338 - accuracy: 0.4514 - val_loss: 1.0495 - val_accuracy: 0.4329 - lr: 0.0010\n",
      "Epoch 254/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.4515\n",
      "Epoch 254: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0344 - accuracy: 0.4515 - val_loss: 1.0608 - val_accuracy: 0.4272 - lr: 0.0010\n",
      "Epoch 255/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.4529\n",
      "Epoch 255: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0336 - accuracy: 0.4529 - val_loss: 1.0369 - val_accuracy: 0.4509 - lr: 0.0010\n",
      "Epoch 256/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0315 - accuracy: 0.4546\n",
      "Epoch 256: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0315 - accuracy: 0.4546 - val_loss: 1.0366 - val_accuracy: 0.4471 - lr: 8.0000e-04\n",
      "Epoch 257/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0316 - accuracy: 0.4537\n",
      "Epoch 257: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0316 - accuracy: 0.4538 - val_loss: 1.0598 - val_accuracy: 0.4250 - lr: 8.0000e-04\n",
      "Epoch 258/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0319 - accuracy: 0.4542\n",
      "Epoch 258: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0319 - accuracy: 0.4542 - val_loss: 1.0357 - val_accuracy: 0.4520 - lr: 8.0000e-04\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0324 - accuracy: 0.4527\n",
      "Epoch 259: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0324 - accuracy: 0.4527 - val_loss: 1.0404 - val_accuracy: 0.4455 - lr: 8.0000e-04\n",
      "Epoch 260/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.4524\n",
      "Epoch 260: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0327 - accuracy: 0.4524 - val_loss: 1.0442 - val_accuracy: 0.4403 - lr: 8.0000e-04\n",
      "Epoch 261/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.4526\n",
      "Epoch 261: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 189s 162ms/step - loss: 1.0321 - accuracy: 0.4526 - val_loss: 1.0402 - val_accuracy: 0.4451 - lr: 8.0000e-04\n",
      "Epoch 262/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0327 - accuracy: 0.4532\n",
      "Epoch 262: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0327 - accuracy: 0.4532 - val_loss: 1.0610 - val_accuracy: 0.4290 - lr: 8.0000e-04\n",
      "Epoch 263/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0329 - accuracy: 0.4520\n",
      "Epoch 263: val_loss did not improve from 1.03518\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0328 - accuracy: 0.4520 - val_loss: 1.0464 - val_accuracy: 0.4358 - lr: 8.0000e-04\n",
      "Epoch 264/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4526\n",
      "Epoch 264: val_loss improved from 1.03518 to 1.03509, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0332 - accuracy: 0.4526 - val_loss: 1.0351 - val_accuracy: 0.4495 - lr: 8.0000e-04\n",
      "Epoch 265/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0327 - accuracy: 0.4548\n",
      "Epoch 265: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 189s 162ms/step - loss: 1.0327 - accuracy: 0.4547 - val_loss: 1.0505 - val_accuracy: 0.4380 - lr: 8.0000e-04\n",
      "Epoch 266/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4533\n",
      "Epoch 266: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0334 - accuracy: 0.4533 - val_loss: 1.0431 - val_accuracy: 0.4417 - lr: 8.0000e-04\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0328 - accuracy: 0.4549\n",
      "Epoch 267: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 191s 164ms/step - loss: 1.0328 - accuracy: 0.4549 - val_loss: 1.0467 - val_accuracy: 0.4302 - lr: 8.0000e-04\n",
      "Epoch 268/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4507\n",
      "Epoch 268: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 187s 161ms/step - loss: 1.0335 - accuracy: 0.4507 - val_loss: 1.0474 - val_accuracy: 0.4479 - lr: 8.0000e-04\n",
      "Epoch 269/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0330 - accuracy: 0.4533\n",
      "Epoch 269: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 187s 161ms/step - loss: 1.0330 - accuracy: 0.4533 - val_loss: 1.0396 - val_accuracy: 0.4424 - lr: 8.0000e-04\n",
      "Epoch 270/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4524\n",
      "Epoch 270: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 190s 163ms/step - loss: 1.0340 - accuracy: 0.4524 - val_loss: 1.0433 - val_accuracy: 0.4402 - lr: 8.0000e-04\n",
      "Epoch 271/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4523\n",
      "Epoch 271: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 192s 165ms/step - loss: 1.0335 - accuracy: 0.4523 - val_loss: 1.0352 - val_accuracy: 0.4518 - lr: 8.0000e-04\n",
      "Epoch 272/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4522\n",
      "Epoch 272: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 193s 166ms/step - loss: 1.0333 - accuracy: 0.4522 - val_loss: 1.0434 - val_accuracy: 0.4408 - lr: 8.0000e-04\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.4541\n",
      "Epoch 273: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 193s 166ms/step - loss: 1.0331 - accuracy: 0.4541 - val_loss: 1.0392 - val_accuracy: 0.4475 - lr: 8.0000e-04\n",
      "Epoch 274/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4521\n",
      "Epoch 274: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 193s 165ms/step - loss: 1.0337 - accuracy: 0.4521 - val_loss: 1.0559 - val_accuracy: 0.4338 - lr: 8.0000e-04\n",
      "Epoch 275/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.4546\n",
      "Epoch 275: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 190s 163ms/step - loss: 1.0328 - accuracy: 0.4546 - val_loss: 1.0422 - val_accuracy: 0.4406 - lr: 8.0000e-04\n",
      "Epoch 276/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.4519\n",
      "Epoch 276: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 201s 172ms/step - loss: 1.0331 - accuracy: 0.4519 - val_loss: 1.0502 - val_accuracy: 0.4375 - lr: 8.0000e-04\n",
      "Epoch 277/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4525\n",
      "Epoch 277: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 201s 173ms/step - loss: 1.0332 - accuracy: 0.4525 - val_loss: 1.0387 - val_accuracy: 0.4427 - lr: 8.0000e-04\n",
      "Epoch 278/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0327 - accuracy: 0.4536\n",
      "Epoch 278: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 201s 172ms/step - loss: 1.0327 - accuracy: 0.4536 - val_loss: 1.0367 - val_accuracy: 0.4461 - lr: 8.0000e-04\n",
      "Epoch 279/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4523\n",
      "Epoch 279: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 201s 173ms/step - loss: 1.0342 - accuracy: 0.4524 - val_loss: 1.0389 - val_accuracy: 0.4478 - lr: 8.0000e-04\n",
      "Epoch 280/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.4544\n",
      "Epoch 280: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 200s 171ms/step - loss: 1.0331 - accuracy: 0.4544 - val_loss: 1.0366 - val_accuracy: 0.4450 - lr: 8.0000e-04\n",
      "Epoch 281/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4532\n",
      "Epoch 281: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 200s 172ms/step - loss: 1.0334 - accuracy: 0.4532 - val_loss: 1.0386 - val_accuracy: 0.4431 - lr: 8.0000e-04\n",
      "Epoch 282/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4519\n",
      "Epoch 282: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 200s 171ms/step - loss: 1.0342 - accuracy: 0.4519 - val_loss: 1.0419 - val_accuracy: 0.4391 - lr: 8.0000e-04\n",
      "Epoch 283/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4527\n",
      "Epoch 283: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 200s 172ms/step - loss: 1.0338 - accuracy: 0.4527 - val_loss: 1.0416 - val_accuracy: 0.4403 - lr: 8.0000e-04\n",
      "Epoch 284/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0330 - accuracy: 0.4533\n",
      "Epoch 284: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 199s 171ms/step - loss: 1.0330 - accuracy: 0.4533 - val_loss: 1.0434 - val_accuracy: 0.4420 - lr: 8.0000e-04\n",
      "Epoch 285/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4532\n",
      "Epoch 285: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 200s 172ms/step - loss: 1.0333 - accuracy: 0.4532 - val_loss: 1.0565 - val_accuracy: 0.4354 - lr: 8.0000e-04\n",
      "Epoch 286/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4525\n",
      "Epoch 286: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 201s 172ms/step - loss: 1.0339 - accuracy: 0.4525 - val_loss: 1.0403 - val_accuracy: 0.4470 - lr: 8.0000e-04\n",
      "Epoch 287/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4532\n",
      "Epoch 287: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 191s 164ms/step - loss: 1.0332 - accuracy: 0.4532 - val_loss: 1.0408 - val_accuracy: 0.4455 - lr: 8.0000e-04\n",
      "Epoch 288/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4531\n",
      "Epoch 288: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 191s 164ms/step - loss: 1.0334 - accuracy: 0.4531 - val_loss: 1.0462 - val_accuracy: 0.4394 - lr: 8.0000e-04\n",
      "Epoch 289/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4520\n",
      "Epoch 289: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 189s 162ms/step - loss: 1.0339 - accuracy: 0.4520 - val_loss: 1.0415 - val_accuracy: 0.4390 - lr: 8.0000e-04\n",
      "Epoch 290/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.4526\n",
      "Epoch 290: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0336 - accuracy: 0.4526 - val_loss: 1.0364 - val_accuracy: 0.4490 - lr: 8.0000e-04\n",
      "Epoch 291/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4532\n",
      "Epoch 291: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0333 - accuracy: 0.4532 - val_loss: 1.0427 - val_accuracy: 0.4401 - lr: 8.0000e-04\n",
      "Epoch 292/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4521\n",
      "Epoch 292: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0338 - accuracy: 0.4520 - val_loss: 1.0489 - val_accuracy: 0.4306 - lr: 8.0000e-04\n",
      "Epoch 293/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4530\n",
      "Epoch 293: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 184s 157ms/step - loss: 1.0335 - accuracy: 0.4531 - val_loss: 1.0394 - val_accuracy: 0.4449 - lr: 8.0000e-04\n",
      "Epoch 294/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4536\n",
      "Epoch 294: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 183s 157ms/step - loss: 1.0334 - accuracy: 0.4536 - val_loss: 1.0519 - val_accuracy: 0.4362 - lr: 8.0000e-04\n",
      "Epoch 295/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4522\n",
      "Epoch 295: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 184s 157ms/step - loss: 1.0335 - accuracy: 0.4522 - val_loss: 1.0502 - val_accuracy: 0.4414 - lr: 8.0000e-04\n",
      "Epoch 296/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4528\n",
      "Epoch 296: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0339 - accuracy: 0.4528 - val_loss: 1.0370 - val_accuracy: 0.4459 - lr: 8.0000e-04\n",
      "Epoch 297/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4536\n",
      "Epoch 297: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 183s 157ms/step - loss: 1.0332 - accuracy: 0.4536 - val_loss: 1.0413 - val_accuracy: 0.4422 - lr: 8.0000e-04\n",
      "Epoch 298/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4525\n",
      "Epoch 298: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0333 - accuracy: 0.4525 - val_loss: 1.0460 - val_accuracy: 0.4404 - lr: 8.0000e-04\n",
      "Epoch 299/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.4522\n",
      "Epoch 299: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0336 - accuracy: 0.4522 - val_loss: 1.0539 - val_accuracy: 0.4327 - lr: 8.0000e-04\n",
      "Epoch 300/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.4532\n",
      "Epoch 300: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 194s 166ms/step - loss: 1.0331 - accuracy: 0.4531 - val_loss: 1.0430 - val_accuracy: 0.4407 - lr: 8.0000e-04\n",
      "Epoch 301/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4525\n",
      "Epoch 301: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 191s 164ms/step - loss: 1.0339 - accuracy: 0.4525 - val_loss: 1.0356 - val_accuracy: 0.4470 - lr: 8.0000e-04\n",
      "Epoch 302/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4520\n",
      "Epoch 302: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0333 - accuracy: 0.4520 - val_loss: 1.0427 - val_accuracy: 0.4450 - lr: 8.0000e-04\n",
      "Epoch 303/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0330 - accuracy: 0.4531\n",
      "Epoch 303: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0330 - accuracy: 0.4530 - val_loss: 1.0384 - val_accuracy: 0.4449 - lr: 8.0000e-04\n",
      "Epoch 304/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.4540\n",
      "Epoch 304: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0328 - accuracy: 0.4540 - val_loss: 1.0490 - val_accuracy: 0.4416 - lr: 8.0000e-04\n",
      "Epoch 305/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4527\n",
      "Epoch 305: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0342 - accuracy: 0.4527 - val_loss: 1.0374 - val_accuracy: 0.4461 - lr: 8.0000e-04\n",
      "Epoch 306/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0310 - accuracy: 0.4553\n",
      "Epoch 306: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 191s 164ms/step - loss: 1.0310 - accuracy: 0.4553 - val_loss: 1.0400 - val_accuracy: 0.4458 - lr: 6.4000e-04\n",
      "Epoch 307/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0315 - accuracy: 0.4554\n",
      "Epoch 307: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 195s 167ms/step - loss: 1.0315 - accuracy: 0.4554 - val_loss: 1.0396 - val_accuracy: 0.4401 - lr: 6.4000e-04\n",
      "Epoch 308/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0319 - accuracy: 0.4550\n",
      "Epoch 308: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0319 - accuracy: 0.4550 - val_loss: 1.0363 - val_accuracy: 0.4478 - lr: 6.4000e-04\n",
      "Epoch 309/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0320 - accuracy: 0.4548\n",
      "Epoch 309: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0320 - accuracy: 0.4548 - val_loss: 1.0420 - val_accuracy: 0.4406 - lr: 6.4000e-04\n",
      "Epoch 310/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0322 - accuracy: 0.4544\n",
      "Epoch 310: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0323 - accuracy: 0.4543 - val_loss: 1.0626 - val_accuracy: 0.4304 - lr: 6.4000e-04\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0325 - accuracy: 0.4538\n",
      "Epoch 311: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 202s 173ms/step - loss: 1.0325 - accuracy: 0.4538 - val_loss: 1.0526 - val_accuracy: 0.4345 - lr: 6.4000e-04\n",
      "Epoch 312/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0329 - accuracy: 0.4529\n",
      "Epoch 312: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0329 - accuracy: 0.4529 - val_loss: 1.0432 - val_accuracy: 0.4388 - lr: 6.4000e-04\n",
      "Epoch 313/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0326 - accuracy: 0.4526\n",
      "Epoch 313: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0326 - accuracy: 0.4526 - val_loss: 1.0379 - val_accuracy: 0.4464 - lr: 6.4000e-04\n",
      "Epoch 314/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0326 - accuracy: 0.4538\n",
      "Epoch 314: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0326 - accuracy: 0.4538 - val_loss: 1.0410 - val_accuracy: 0.4417 - lr: 6.4000e-04\n",
      "Epoch 315/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0329 - accuracy: 0.4539\n",
      "Epoch 315: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0329 - accuracy: 0.4539 - val_loss: 1.0414 - val_accuracy: 0.4398 - lr: 6.4000e-04\n",
      "Epoch 316/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0329 - accuracy: 0.4533\n",
      "Epoch 316: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 202s 173ms/step - loss: 1.0329 - accuracy: 0.4533 - val_loss: 1.0360 - val_accuracy: 0.4486 - lr: 6.4000e-04\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.4520\n",
      "Epoch 317: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0331 - accuracy: 0.4520 - val_loss: 1.0355 - val_accuracy: 0.4502 - lr: 6.4000e-04\n",
      "Epoch 318/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4527\n",
      "Epoch 318: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0334 - accuracy: 0.4527 - val_loss: 1.0512 - val_accuracy: 0.4302 - lr: 6.4000e-04\n",
      "Epoch 319/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4524\n",
      "Epoch 319: val_loss did not improve from 1.03509\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0332 - accuracy: 0.4524 - val_loss: 1.0398 - val_accuracy: 0.4462 - lr: 6.4000e-04\n",
      "Epoch 320/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4523\n",
      "Epoch 320: val_loss improved from 1.03509 to 1.03442, saving model to best_model_5.h5\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0332 - accuracy: 0.4523 - val_loss: 1.0344 - val_accuracy: 0.4514 - lr: 6.4000e-04\n",
      "Epoch 321/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.4529\n",
      "Epoch 321: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0328 - accuracy: 0.4529 - val_loss: 1.0351 - val_accuracy: 0.4484 - lr: 6.4000e-04\n",
      "Epoch 322/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4534\n",
      "Epoch 322: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0338 - accuracy: 0.4534 - val_loss: 1.0403 - val_accuracy: 0.4434 - lr: 6.4000e-04\n",
      "Epoch 323/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0341 - accuracy: 0.4518\n",
      "Epoch 323: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 200s 172ms/step - loss: 1.0341 - accuracy: 0.4518 - val_loss: 1.0369 - val_accuracy: 0.4492 - lr: 6.4000e-04\n",
      "Epoch 324/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4516\n",
      "Epoch 324: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0335 - accuracy: 0.4516 - val_loss: 1.0350 - val_accuracy: 0.4507 - lr: 6.4000e-04\n",
      "Epoch 325/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4520\n",
      "Epoch 325: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 161ms/step - loss: 1.0334 - accuracy: 0.4521 - val_loss: 1.0579 - val_accuracy: 0.4288 - lr: 6.4000e-04\n",
      "Epoch 326/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4523\n",
      "Epoch 326: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0343 - accuracy: 0.4523 - val_loss: 1.0398 - val_accuracy: 0.4498 - lr: 6.4000e-04\n",
      "Epoch 327/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4535\n",
      "Epoch 327: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0333 - accuracy: 0.4535 - val_loss: 1.0378 - val_accuracy: 0.4502 - lr: 6.4000e-04\n",
      "Epoch 328/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.4534\n",
      "Epoch 328: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0331 - accuracy: 0.4534 - val_loss: 1.0377 - val_accuracy: 0.4481 - lr: 6.4000e-04\n",
      "Epoch 329/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4527\n",
      "Epoch 329: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0334 - accuracy: 0.4527 - val_loss: 1.0435 - val_accuracy: 0.4491 - lr: 6.4000e-04\n",
      "Epoch 330/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0330 - accuracy: 0.4539\n",
      "Epoch 330: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0330 - accuracy: 0.4539 - val_loss: 1.0468 - val_accuracy: 0.4364 - lr: 6.4000e-04\n",
      "Epoch 331/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.4514\n",
      "Epoch 331: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0344 - accuracy: 0.4515 - val_loss: 1.0507 - val_accuracy: 0.4379 - lr: 6.4000e-04\n",
      "Epoch 332/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4536\n",
      "Epoch 332: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 205s 175ms/step - loss: 1.0332 - accuracy: 0.4536 - val_loss: 1.0447 - val_accuracy: 0.4415 - lr: 6.4000e-04\n",
      "Epoch 333/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4527\n",
      "Epoch 333: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 203s 174ms/step - loss: 1.0337 - accuracy: 0.4527 - val_loss: 1.0395 - val_accuracy: 0.4454 - lr: 6.4000e-04\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.4538\n",
      "Epoch 334: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 204s 175ms/step - loss: 1.0331 - accuracy: 0.4538 - val_loss: 1.0672 - val_accuracy: 0.4227 - lr: 6.4000e-04\n",
      "Epoch 335/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4512\n",
      "Epoch 335: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 197s 169ms/step - loss: 1.0342 - accuracy: 0.4511 - val_loss: 1.0551 - val_accuracy: 0.4361 - lr: 6.4000e-04\n",
      "Epoch 336/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.4525\n",
      "Epoch 336: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0336 - accuracy: 0.4525 - val_loss: 1.0383 - val_accuracy: 0.4455 - lr: 6.4000e-04\n",
      "Epoch 337/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4531\n",
      "Epoch 337: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0340 - accuracy: 0.4531 - val_loss: 1.0422 - val_accuracy: 0.4405 - lr: 6.4000e-04\n",
      "Epoch 338/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0331 - accuracy: 0.4536\n",
      "Epoch 338: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0331 - accuracy: 0.4536 - val_loss: 1.0448 - val_accuracy: 0.4431 - lr: 6.4000e-04\n",
      "Epoch 339/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4517\n",
      "Epoch 339: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0334 - accuracy: 0.4517 - val_loss: 1.0413 - val_accuracy: 0.4478 - lr: 6.4000e-04\n",
      "Epoch 340/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4509\n",
      "Epoch 340: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0338 - accuracy: 0.4509 - val_loss: 1.0395 - val_accuracy: 0.4427 - lr: 6.4000e-04\n",
      "Epoch 341/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4505\n",
      "Epoch 341: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0348 - accuracy: 0.4505 - val_loss: 1.0431 - val_accuracy: 0.4420 - lr: 6.4000e-04\n",
      "Epoch 342/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4536\n",
      "Epoch 342: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0333 - accuracy: 0.4536 - val_loss: 1.0446 - val_accuracy: 0.4489 - lr: 6.4000e-04\n",
      "Epoch 343/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4526\n",
      "Epoch 343: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0339 - accuracy: 0.4526 - val_loss: 1.0512 - val_accuracy: 0.4318 - lr: 6.4000e-04\n",
      "Epoch 344/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0341 - accuracy: 0.4522\n",
      "Epoch 344: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0341 - accuracy: 0.4522 - val_loss: 1.0350 - val_accuracy: 0.4511 - lr: 6.4000e-04\n",
      "Epoch 345/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4532\n",
      "Epoch 345: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0336 - accuracy: 0.4532 - val_loss: 1.0648 - val_accuracy: 0.4274 - lr: 6.4000e-04\n",
      "Epoch 346/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4532\n",
      "Epoch 346: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0339 - accuracy: 0.4532 - val_loss: 1.0480 - val_accuracy: 0.4378 - lr: 6.4000e-04\n",
      "Epoch 347/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4527\n",
      "Epoch 347: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0340 - accuracy: 0.4528 - val_loss: 1.0373 - val_accuracy: 0.4481 - lr: 6.4000e-04\n",
      "Epoch 348/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4525\n",
      "Epoch 348: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0337 - accuracy: 0.4524 - val_loss: 1.0387 - val_accuracy: 0.4398 - lr: 6.4000e-04\n",
      "Epoch 349/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.4528\n",
      "Epoch 349: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0345 - accuracy: 0.4528 - val_loss: 1.0400 - val_accuracy: 0.4404 - lr: 6.4000e-04\n",
      "Epoch 350/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.4535\n",
      "Epoch 350: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0336 - accuracy: 0.4535 - val_loss: 1.0505 - val_accuracy: 0.4320 - lr: 6.4000e-04\n",
      "Epoch 351/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4542\n",
      "Epoch 351: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0337 - accuracy: 0.4542 - val_loss: 1.0415 - val_accuracy: 0.4404 - lr: 6.4000e-04\n",
      "Epoch 352/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4530\n",
      "Epoch 352: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0340 - accuracy: 0.4530 - val_loss: 1.0377 - val_accuracy: 0.4483 - lr: 6.4000e-04\n",
      "Epoch 353/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4540\n",
      "Epoch 353: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0332 - accuracy: 0.4541 - val_loss: 1.0416 - val_accuracy: 0.4454 - lr: 6.4000e-04\n",
      "Epoch 354/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4519\n",
      "Epoch 354: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0343 - accuracy: 0.4519 - val_loss: 1.0516 - val_accuracy: 0.4404 - lr: 6.4000e-04\n",
      "Epoch 355/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4531\n",
      "Epoch 355: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0332 - accuracy: 0.4531 - val_loss: 1.0386 - val_accuracy: 0.4456 - lr: 6.4000e-04\n",
      "Epoch 356/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4520\n",
      "Epoch 356: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0338 - accuracy: 0.4520 - val_loss: 1.0573 - val_accuracy: 0.4309 - lr: 6.4000e-04\n",
      "Epoch 357/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4544\n",
      "Epoch 357: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0334 - accuracy: 0.4543 - val_loss: 1.0717 - val_accuracy: 0.4262 - lr: 6.4000e-04\n",
      "Epoch 358/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4540\n",
      "Epoch 358: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0334 - accuracy: 0.4540 - val_loss: 1.0422 - val_accuracy: 0.4447 - lr: 6.4000e-04\n",
      "Epoch 359/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4526\n",
      "Epoch 359: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0338 - accuracy: 0.4526 - val_loss: 1.0567 - val_accuracy: 0.4267 - lr: 6.4000e-04\n",
      "Epoch 360/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4516\n",
      "Epoch 360: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0343 - accuracy: 0.4516 - val_loss: 1.0528 - val_accuracy: 0.4275 - lr: 6.4000e-04\n",
      "Epoch 361/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0338 - accuracy: 0.4527\n",
      "Epoch 361: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 189s 162ms/step - loss: 1.0338 - accuracy: 0.4527 - val_loss: 1.0401 - val_accuracy: 0.4440 - lr: 6.4000e-04\n",
      "Epoch 362/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0341 - accuracy: 0.4517\n",
      "Epoch 362: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0341 - accuracy: 0.4517 - val_loss: 1.0409 - val_accuracy: 0.4420 - lr: 6.4000e-04\n",
      "Epoch 363/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4515\n",
      "Epoch 363: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0345 - accuracy: 0.4515 - val_loss: 1.0385 - val_accuracy: 0.4461 - lr: 6.4000e-04\n",
      "Epoch 364/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4510\n",
      "Epoch 364: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0339 - accuracy: 0.4510 - val_loss: 1.0534 - val_accuracy: 0.4356 - lr: 6.4000e-04\n",
      "Epoch 365/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4529\n",
      "Epoch 365: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0339 - accuracy: 0.4529 - val_loss: 1.0478 - val_accuracy: 0.4423 - lr: 6.4000e-04\n",
      "Epoch 366/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4532\n",
      "Epoch 366: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0334 - accuracy: 0.4532 - val_loss: 1.0456 - val_accuracy: 0.4403 - lr: 6.4000e-04\n",
      "Epoch 367/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4526\n",
      "Epoch 367: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0335 - accuracy: 0.4526 - val_loss: 1.0472 - val_accuracy: 0.4362 - lr: 6.4000e-04\n",
      "Epoch 368/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0339 - accuracy: 0.4526\n",
      "Epoch 368: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0339 - accuracy: 0.4526 - val_loss: 1.0381 - val_accuracy: 0.4493 - lr: 6.4000e-04\n",
      "Epoch 369/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0335 - accuracy: 0.4532\n",
      "Epoch 369: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0335 - accuracy: 0.4532 - val_loss: 1.0407 - val_accuracy: 0.4463 - lr: 6.4000e-04\n",
      "Epoch 370/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4544\n",
      "Epoch 370: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0332 - accuracy: 0.4543 - val_loss: 1.0391 - val_accuracy: 0.4474 - lr: 6.4000e-04\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.4540\n",
      "Epoch 371: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0317 - accuracy: 0.4540 - val_loss: 1.0488 - val_accuracy: 0.4374 - lr: 5.1200e-04\n",
      "Epoch 372/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0323 - accuracy: 0.4547\n",
      "Epoch 372: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 198s 170ms/step - loss: 1.0323 - accuracy: 0.4547 - val_loss: 1.0562 - val_accuracy: 0.4354 - lr: 5.1200e-04\n",
      "Epoch 373/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.4547\n",
      "Epoch 373: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 194s 167ms/step - loss: 1.0321 - accuracy: 0.4547 - val_loss: 1.0531 - val_accuracy: 0.4305 - lr: 5.1200e-04\n",
      "Epoch 374/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.4538\n",
      "Epoch 374: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 194s 167ms/step - loss: 1.0328 - accuracy: 0.4538 - val_loss: 1.0397 - val_accuracy: 0.4484 - lr: 5.1200e-04\n",
      "Epoch 375/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0324 - accuracy: 0.4541\n",
      "Epoch 375: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 188s 162ms/step - loss: 1.0324 - accuracy: 0.4541 - val_loss: 1.0415 - val_accuracy: 0.4434 - lr: 5.1200e-04\n",
      "Epoch 376/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.4532\n",
      "Epoch 376: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0332 - accuracy: 0.4532 - val_loss: 1.0672 - val_accuracy: 0.4241 - lr: 5.1200e-04\n",
      "Epoch 377/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0337 - accuracy: 0.4510\n",
      "Epoch 377: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0336 - accuracy: 0.4510 - val_loss: 1.0525 - val_accuracy: 0.4300 - lr: 5.1200e-04\n",
      "Epoch 378/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0340 - accuracy: 0.4529\n",
      "Epoch 378: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0340 - accuracy: 0.4529 - val_loss: 1.0552 - val_accuracy: 0.4288 - lr: 5.1200e-04\n",
      "Epoch 379/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4523\n",
      "Epoch 379: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0334 - accuracy: 0.4523 - val_loss: 1.0427 - val_accuracy: 0.4448 - lr: 5.1200e-04\n",
      "Epoch 380/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.4531\n",
      "Epoch 380: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0332 - accuracy: 0.4532 - val_loss: 1.0411 - val_accuracy: 0.4462 - lr: 5.1200e-04\n",
      "Epoch 381/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4535\n",
      "Epoch 381: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0343 - accuracy: 0.4536 - val_loss: 1.0459 - val_accuracy: 0.4411 - lr: 5.1200e-04\n",
      "Epoch 382/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4518\n",
      "Epoch 382: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 159ms/step - loss: 1.0343 - accuracy: 0.4518 - val_loss: 1.0457 - val_accuracy: 0.4443 - lr: 5.1200e-04\n",
      "Epoch 383/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4520\n",
      "Epoch 383: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0345 - accuracy: 0.4520 - val_loss: 1.0488 - val_accuracy: 0.4335 - lr: 5.1200e-04\n",
      "Epoch 384/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0334 - accuracy: 0.4539\n",
      "Epoch 384: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0334 - accuracy: 0.4539 - val_loss: 1.0419 - val_accuracy: 0.4399 - lr: 5.1200e-04\n",
      "Epoch 385/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4524\n",
      "Epoch 385: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0345 - accuracy: 0.4524 - val_loss: 1.0727 - val_accuracy: 0.4254 - lr: 5.1200e-04\n",
      "Epoch 386/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4531\n",
      "Epoch 386: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0342 - accuracy: 0.4531 - val_loss: 1.0707 - val_accuracy: 0.4221 - lr: 5.1200e-04\n",
      "Epoch 387/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.4526\n",
      "Epoch 387: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0342 - accuracy: 0.4526 - val_loss: 1.0463 - val_accuracy: 0.4431 - lr: 5.1200e-04\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0349 - accuracy: 0.4527\n",
      "Epoch 388: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0349 - accuracy: 0.4527 - val_loss: 1.0437 - val_accuracy: 0.4473 - lr: 5.1200e-04\n",
      "Epoch 389/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.4523\n",
      "Epoch 389: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0346 - accuracy: 0.4523 - val_loss: 1.0586 - val_accuracy: 0.4355 - lr: 5.1200e-04\n",
      "Epoch 390/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.4494\n",
      "Epoch 390: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0344 - accuracy: 0.4494 - val_loss: 1.0378 - val_accuracy: 0.4494 - lr: 5.1200e-04\n",
      "Epoch 391/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4530\n",
      "Epoch 391: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 186s 160ms/step - loss: 1.0349 - accuracy: 0.4530 - val_loss: 1.0578 - val_accuracy: 0.4391 - lr: 5.1200e-04\n",
      "Epoch 392/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0341 - accuracy: 0.4517\n",
      "Epoch 392: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0341 - accuracy: 0.4517 - val_loss: 1.0533 - val_accuracy: 0.4390 - lr: 5.1200e-04\n",
      "Epoch 393/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4529\n",
      "Epoch 393: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0349 - accuracy: 0.4529 - val_loss: 1.0386 - val_accuracy: 0.4438 - lr: 5.1200e-04\n",
      "Epoch 394/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0355 - accuracy: 0.4514\n",
      "Epoch 394: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0355 - accuracy: 0.4514 - val_loss: 1.0401 - val_accuracy: 0.4457 - lr: 5.1200e-04\n",
      "Epoch 395/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.4527\n",
      "Epoch 395: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 158ms/step - loss: 1.0343 - accuracy: 0.4527 - val_loss: 1.0415 - val_accuracy: 0.4495 - lr: 5.1200e-04\n",
      "Epoch 396/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4516\n",
      "Epoch 396: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0352 - accuracy: 0.4516 - val_loss: 1.0358 - val_accuracy: 0.4492 - lr: 5.1200e-04\n",
      "Epoch 397/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4508\n",
      "Epoch 397: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0349 - accuracy: 0.4508 - val_loss: 1.0599 - val_accuracy: 0.4315 - lr: 5.1200e-04\n",
      "Epoch 398/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4522\n",
      "Epoch 398: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0347 - accuracy: 0.4523 - val_loss: 1.0441 - val_accuracy: 0.4395 - lr: 5.1200e-04\n",
      "Epoch 399/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4515\n",
      "Epoch 399: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0348 - accuracy: 0.4515 - val_loss: 1.0505 - val_accuracy: 0.4394 - lr: 5.1200e-04\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0346 - accuracy: 0.4522\n",
      "Epoch 400: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0346 - accuracy: 0.4522 - val_loss: 1.0393 - val_accuracy: 0.4439 - lr: 5.1200e-04\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.4525\n",
      "Epoch 401: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0350 - accuracy: 0.4525 - val_loss: 1.0391 - val_accuracy: 0.4461 - lr: 5.1200e-04\n",
      "Epoch 402/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.4513\n",
      "Epoch 402: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0345 - accuracy: 0.4513 - val_loss: 1.0420 - val_accuracy: 0.4345 - lr: 5.1200e-04\n",
      "Epoch 403/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.4504\n",
      "Epoch 403: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0354 - accuracy: 0.4504 - val_loss: 1.0390 - val_accuracy: 0.4456 - lr: 5.1200e-04\n",
      "Epoch 404/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4510\n",
      "Epoch 404: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0352 - accuracy: 0.4510 - val_loss: 1.0392 - val_accuracy: 0.4457 - lr: 5.1200e-04\n",
      "Epoch 405/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.4536\n",
      "Epoch 405: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0346 - accuracy: 0.4537 - val_loss: 1.0594 - val_accuracy: 0.4235 - lr: 5.1200e-04\n",
      "Epoch 406/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.4543\n",
      "Epoch 406: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0349 - accuracy: 0.4543 - val_loss: 1.0430 - val_accuracy: 0.4408 - lr: 5.1200e-04\n",
      "Epoch 407/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.4500\n",
      "Epoch 407: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0353 - accuracy: 0.4500 - val_loss: 1.0390 - val_accuracy: 0.4493 - lr: 5.1200e-04\n",
      "Epoch 408/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0356 - accuracy: 0.4522\n",
      "Epoch 408: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 187s 160ms/step - loss: 1.0356 - accuracy: 0.4522 - val_loss: 1.0692 - val_accuracy: 0.4291 - lr: 5.1200e-04\n",
      "Epoch 409/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4523\n",
      "Epoch 409: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0347 - accuracy: 0.4523 - val_loss: 1.0493 - val_accuracy: 0.4401 - lr: 5.1200e-04\n",
      "Epoch 410/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.4511\n",
      "Epoch 410: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0354 - accuracy: 0.4511 - val_loss: 1.0595 - val_accuracy: 0.4300 - lr: 5.1200e-04\n",
      "Epoch 411/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0358 - accuracy: 0.4511\n",
      "Epoch 411: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0358 - accuracy: 0.4511 - val_loss: 1.0464 - val_accuracy: 0.4394 - lr: 5.1200e-04\n",
      "Epoch 412/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.4509\n",
      "Epoch 412: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0347 - accuracy: 0.4509 - val_loss: 1.0522 - val_accuracy: 0.4361 - lr: 5.1200e-04\n",
      "Epoch 413/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4534\n",
      "Epoch 413: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0352 - accuracy: 0.4534 - val_loss: 1.0417 - val_accuracy: 0.4408 - lr: 5.1200e-04\n",
      "Epoch 414/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0350 - accuracy: 0.4512\n",
      "Epoch 414: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0350 - accuracy: 0.4512 - val_loss: 1.0760 - val_accuracy: 0.4103 - lr: 5.1200e-04\n",
      "Epoch 415/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0355 - accuracy: 0.4520\n",
      "Epoch 415: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0355 - accuracy: 0.4520 - val_loss: 1.0714 - val_accuracy: 0.4142 - lr: 5.1200e-04\n",
      "Epoch 416/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0350 - accuracy: 0.4510\n",
      "Epoch 416: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0350 - accuracy: 0.4510 - val_loss: 1.0416 - val_accuracy: 0.4452 - lr: 5.1200e-04\n",
      "Epoch 417/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0348 - accuracy: 0.4529\n",
      "Epoch 417: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0348 - accuracy: 0.4529 - val_loss: 1.0435 - val_accuracy: 0.4425 - lr: 5.1200e-04\n",
      "Epoch 418/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0351 - accuracy: 0.4510\n",
      "Epoch 418: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 188s 161ms/step - loss: 1.0351 - accuracy: 0.4510 - val_loss: 1.0529 - val_accuracy: 0.4247 - lr: 5.1200e-04\n",
      "Epoch 419/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4526\n",
      "Epoch 419: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 185s 159ms/step - loss: 1.0352 - accuracy: 0.4526 - val_loss: 1.0611 - val_accuracy: 0.4201 - lr: 5.1200e-04\n",
      "Epoch 420/1000\n",
      "1165/1166 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.4519Restoring model weights from the end of the best epoch: 320.\n",
      "\n",
      "Epoch 420: val_loss did not improve from 1.03442\n",
      "1166/1166 [==============================] - 184s 158ms/step - loss: 1.0352 - accuracy: 0.4519 - val_loss: 1.0558 - val_accuracy: 0.4342 - lr: 5.1200e-04\n",
      "Epoch 420: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 생성 및 학습\n",
    "input_shape = X.shape[1:]  # 10분 동안의 데이터 \n",
    "model = create_transformer_model(input_shape, num_heads=4, ff_dim=128, d_model=128, num_classes=3)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=1000, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 18s 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.56      0.50     13036\n",
      "           1       0.43      0.30      0.36     11419\n",
      "           2       0.46      0.47      0.47     12833\n",
      "\n",
      "    accuracy                           0.45     37288\n",
      "   macro avg       0.45      0.45      0.44     37288\n",
      "weighted avg       0.45      0.45      0.45     37288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 성능 평가 지표\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 시각화\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 정확도 시각화\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
