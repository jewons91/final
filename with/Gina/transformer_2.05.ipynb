{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순 클래스로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('./000660.csv')\n",
    "\n",
    "# 데이터 칼럼명 변경\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        '시가': 'Open',\n",
    "        '고가': 'High',\n",
    "        '저가': 'Low',\n",
    "        '종가': 'Close',\n",
    "        '거래량': 'Total_Volume',\n",
    "        '매도량': 'Sell_Volume',\n",
    "        '매수량': 'Buy_Volume'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 선택\n",
    "# 가격 관련\n",
    "price_features = ['Open', 'High', 'Low', 'Close']\n",
    "# 거래량 관련\n",
    "volume_features = ['Buy_Volume', 'Sell_Volume', 'Total_Volume']\n",
    "# 모든 특성 리스트\n",
    "features = price_features + volume_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래량 강도 계산\n",
    "data['Volume_Intensity'] = data['Buy_Volume'] - data['Sell_Volume']\n",
    "data['Volume_Intensity_Ratio'] = data['Volume_Intensity'] / (data['Total_Volume'] + 1e-5)  # 0으로 나누는 것 방지\n",
    "data['Buy_Sell_Ratio'] = data['Buy_Volume'] / (data['Sell_Volume'] + 1e-5)\n",
    "\n",
    "# 새로운 특성들을 특성 리스트에 추가\n",
    "features.extend(['Volume_Intensity', 'Volume_Intensity_Ratio', 'Buy_Sell_Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 딕셔너리 생성\n",
    "scalers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 관련 특성 스케일링\n",
    "for feature in price_features:\n",
    "    scaler = StandardScaler()\n",
    "    data[feature] = scaler.fit_transform(data[[feature]])\n",
    "    scalers[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래량 관련 특성 스케일링\n",
    "for feature in volume_features + ['Volume_Intensity', 'Volume_Intensity_Ratio', 'Buy_Sell_Ratio']:\n",
    "    scaler = RobustScaler()\n",
    "    data[feature] = scaler.fit_transform(data[[feature]])\n",
    "    scalers[feature] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 급변 레이블링\n",
    "price_threshold = 0.01  # 0.5 이상 변동 시 급변으로 간주\n",
    "\n",
    "data['Price_Change'] = data['Close'].pct_change()\n",
    "data = data.dropna()  # 첫 번째 행 제거\n",
    "\n",
    "def label_price_change(change):\n",
    "    if change >= price_threshold:\n",
    "        return 2  # 상승 급변\n",
    "    elif change <= -price_threshold:\n",
    "        return 0  # 하락 급변\n",
    "    else:\n",
    "        return 1  # 보합\n",
    "\n",
    "data['Price_Label'] = data['Price_Change'].apply(label_price_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래량 강도 급변 레이블링\n",
    "intensity_threshold = data['Volume_Intensity'].std() * 2  # 표준편차의 2배를 기준으로 설정\n",
    "\n",
    "def label_intensity(intensity):\n",
    "    if intensity >= intensity_threshold:\n",
    "        return 1  # 강한 매수세\n",
    "    elif intensity <= -intensity_threshold:\n",
    "        return -1  # 강한 매도세\n",
    "    else:\n",
    "        return 0  # 중립\n",
    "\n",
    "data['Intensity_Label'] = data['Volume_Intensity'].apply(label_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합 레이블링\n",
    "def combined_label(row):\n",
    "    if row['Price_Label'] == 2 and row['Intensity_Label'] == 1:\n",
    "        return 3  # 상승 급변 + 강한 매수세\n",
    "    elif row['Price_Label'] == 0 and row['Intensity_Label'] == -1:\n",
    "        return -3  # 하락 급변 + 강한 매도세\n",
    "    else:\n",
    "        return row['Price_Label']  # 기존 가격 레이블 유지\n",
    "\n",
    "data['Combined_Label'] = data.apply(combined_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 값 재매핑 사전 생성\n",
    "label_mapping = {\n",
    "    -3: 0,  # 하락 급변 + 강한 매도세\n",
    "     0: 1,  # 하락\n",
    "     1: 2,  # 보합\n",
    "     2: 3,  # 상승\n",
    "     3: 4   # 상승 급변 + 강한 매수세\n",
    "}\n",
    "\n",
    "# 레이블 재매핑 함수 정의\n",
    "def remap_labels(label):\n",
    "    return label_mapping[label]\n",
    "\n",
    "# 레이블 재매핑 적용\n",
    "data['Combined_Label'] = data['Combined_Label'].map(remap_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 생성 함수 정의\n",
    "def create_sequences(data, sequence_length, target):\n",
    "    X = []\n",
    "    y = []\n",
    "    data_values = data[features].values\n",
    "    labels = data[target].values\n",
    "    for i in range(len(data_values) - sequence_length):\n",
    "        X.append(data_values[i:i+sequence_length])\n",
    "        y.append(labels[i+sequence_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "sequence_length = 60  # 시퀀스 길이\n",
    "X, y = create_sequences(data, sequence_length, target='Price_Label')  # 또는 'Price_Label', 'Intensity_Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 순서대로 데이터 분할\n",
    "train_size = int(len(X) * 0.7)\n",
    "val_size = int(len(X) * 0.15)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "X_val = X[train_size:train_size+val_size]\n",
    "y_val = y[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X[train_size+val_size:]\n",
    "y_test = y[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "d_model = X_train.shape[2]  # 입력 특성의 차원\n",
    "num_heads = 8\n",
    "ff_dim = 128\n",
    "num_layers = 4\n",
    "dropout_rate = 0.2\n",
    "num_classes = len(label_mapping) # 레이블 클래스 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 정의\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(sequence_length, d_model)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            np.arange(position)[:, np.newaxis],\n",
    "            np.arange(d_model)[np.newaxis, :],\n",
    "            d_model)\n",
    "        \n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 블록 정의\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attn_output = layers.Dropout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "    \n",
    "    # Feed Forward Network\n",
    "    ffn_output = layers.Dense(ff_dim, activation='gelu', kernel_regularizer=regularizers.l2(1e-4))(out1)\n",
    "    ffn_output = layers.Dense(head_size)(ffn_output)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 60, 10)]     0           []                               \n",
      "                                                                                                  \n",
      " positional_encoding (Positiona  (None, 60, 10)      0           ['input_1[0][0]']                \n",
      " lEncoding)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 60, 10)      3450        ['positional_encoding[0][0]',    \n",
      " dAttention)                                                      'positional_encoding[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 60, 10)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 60, 10)      0           ['positional_encoding[0][0]',    \n",
      " da)                                                              'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 60, 10)      20          ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60, 128)      1408        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 10)       1290        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 60, 10)       0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 60, 10)      0           ['layer_normalization[0][0]',    \n",
      " mbda)                                                            'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 60, 10)      3450        ['layer_normalization_1[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 60, 10)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 60, 128)      1408        ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 60, 10)       1290        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 60, 10)       0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 60, 10)      3450        ['layer_normalization_3[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 60, 10)       0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 60, 128)      1408        ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 60, 10)       1290        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 60, 10)       0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 60, 10)      3450        ['layer_normalization_5[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 60, 10)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 60, 128)      1408        ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 60, 10)       1290        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 60, 10)       0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 60, 10)      0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 60, 10)      20          ['tf.__operators__.add_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 10)          0           ['layer_normalization_7[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 10)           0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 5)            55          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,807\n",
      "Trainable params: 24,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "def create_model():\n",
    "    inputs = layers.Input(shape=(sequence_length, d_model))\n",
    "    x = PositionalEncoding(sequence_length, d_model)(inputs)\n",
    "    \n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_block(x, d_model, num_heads, ff_dim, dropout_rate)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8167/8167 [==============================] - 270s 33ms/step - loss: 0.9551 - accuracy: 0.6355 - val_loss: 3.3025 - val_accuracy: 0.0742\n",
      "Epoch 2/100\n",
      "8167/8167 [==============================] - 261s 32ms/step - loss: 0.8709 - accuracy: 0.6694 - val_loss: 3.0333 - val_accuracy: 0.0743\n",
      "Epoch 3/100\n",
      "8167/8167 [==============================] - 257s 31ms/step - loss: 0.8589 - accuracy: 0.6727 - val_loss: 2.9045 - val_accuracy: 0.0745\n",
      "Epoch 4/100\n",
      "8167/8167 [==============================] - 264s 32ms/step - loss: 0.8483 - accuracy: 0.6743 - val_loss: 2.6439 - val_accuracy: 0.0750\n",
      "Epoch 5/100\n",
      "8167/8167 [==============================] - 241s 30ms/step - loss: 0.8382 - accuracy: 0.6783 - val_loss: 2.3373 - val_accuracy: 0.0750\n",
      "Epoch 6/100\n",
      "8167/8167 [==============================] - 241s 29ms/step - loss: 0.8281 - accuracy: 0.6850 - val_loss: 1.9268 - val_accuracy: 0.0775\n",
      "Epoch 7/100\n",
      "8167/8167 [==============================] - 241s 29ms/step - loss: 0.8218 - accuracy: 0.6888 - val_loss: 1.6088 - val_accuracy: 0.0775\n",
      "Epoch 8/100\n",
      "8167/8167 [==============================] - 241s 29ms/step - loss: 0.8148 - accuracy: 0.6932 - val_loss: 1.3150 - val_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "8167/8167 [==============================] - 258s 32ms/step - loss: 0.8102 - accuracy: 0.6957 - val_loss: 1.0790 - val_accuracy: 0.5987\n",
      "Epoch 10/100\n",
      "8167/8167 [==============================] - 241s 30ms/step - loss: 0.8060 - accuracy: 0.6985 - val_loss: 0.9973 - val_accuracy: 0.6388\n",
      "Epoch 11/100\n",
      "8167/8167 [==============================] - 262s 32ms/step - loss: 0.8051 - accuracy: 0.7009 - val_loss: 0.9055 - val_accuracy: 0.6728\n",
      "Epoch 12/100\n",
      "8167/8167 [==============================] - 266s 33ms/step - loss: 0.8021 - accuracy: 0.7029 - val_loss: 0.7380 - val_accuracy: 0.7288\n",
      "Epoch 13/100\n",
      "8167/8167 [==============================] - 267s 33ms/step - loss: 0.8008 - accuracy: 0.7043 - val_loss: 0.7279 - val_accuracy: 0.7272\n",
      "Epoch 14/100\n",
      "8167/8167 [==============================] - 251s 31ms/step - loss: 0.7977 - accuracy: 0.7065 - val_loss: 0.6971 - val_accuracy: 0.7339\n",
      "Epoch 15/100\n",
      "8167/8167 [==============================] - 264s 32ms/step - loss: 0.7969 - accuracy: 0.7082 - val_loss: 0.6618 - val_accuracy: 0.7427\n",
      "Epoch 16/100\n",
      "8167/8167 [==============================] - 265s 32ms/step - loss: 0.7959 - accuracy: 0.7080 - val_loss: 0.6137 - val_accuracy: 0.7552\n",
      "Epoch 17/100\n",
      "8167/8167 [==============================] - 261s 32ms/step - loss: 0.7937 - accuracy: 0.7091 - val_loss: 0.6257 - val_accuracy: 0.7487\n",
      "Epoch 18/100\n",
      "8167/8167 [==============================] - 251s 31ms/step - loss: 0.7926 - accuracy: 0.7093 - val_loss: 0.6144 - val_accuracy: 0.7521\n",
      "Epoch 19/100\n",
      "8167/8167 [==============================] - 265s 32ms/step - loss: 0.7909 - accuracy: 0.7093 - val_loss: 0.5876 - val_accuracy: 0.7597\n",
      "Epoch 20/100\n",
      "8167/8167 [==============================] - 267s 33ms/step - loss: 0.7909 - accuracy: 0.7105 - val_loss: 0.5705 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "8167/8167 [==============================] - 267s 33ms/step - loss: 0.7914 - accuracy: 0.7086 - val_loss: 0.5621 - val_accuracy: 0.7686\n",
      "Epoch 22/100\n",
      "8167/8167 [==============================] - 267s 33ms/step - loss: 0.7902 - accuracy: 0.7103 - val_loss: 0.5537 - val_accuracy: 0.7693\n",
      "Epoch 23/100\n",
      "8167/8167 [==============================] - 267s 33ms/step - loss: 0.7890 - accuracy: 0.7114 - val_loss: 0.5384 - val_accuracy: 0.7785\n",
      "Epoch 24/100\n",
      "8167/8167 [==============================] - 266s 33ms/step - loss: 0.7879 - accuracy: 0.7125 - val_loss: 0.6080 - val_accuracy: 0.7492\n",
      "Epoch 25/100\n",
      "8167/8167 [==============================] - 268s 33ms/step - loss: 0.7875 - accuracy: 0.7129 - val_loss: 0.5746 - val_accuracy: 0.7603\n",
      "Epoch 26/100\n",
      "8167/8167 [==============================] - 266s 33ms/step - loss: 0.7863 - accuracy: 0.7125 - val_loss: 0.5568 - val_accuracy: 0.7664\n",
      "Epoch 27/100\n",
      "8167/8167 [==============================] - 268s 33ms/step - loss: 0.7868 - accuracy: 0.7129 - val_loss: 0.5558 - val_accuracy: 0.7682\n",
      "Epoch 28/100\n",
      "8167/8167 [==============================] - 268s 33ms/step - loss: 0.7867 - accuracy: 0.7125 - val_loss: 0.5274 - val_accuracy: 0.7815\n",
      "Epoch 29/100\n",
      "8167/8167 [==============================] - 269s 33ms/step - loss: 0.7852 - accuracy: 0.7132 - val_loss: 0.5335 - val_accuracy: 0.7762\n",
      "Epoch 30/100\n",
      "8167/8167 [==============================] - 257s 31ms/step - loss: 0.7854 - accuracy: 0.7135 - val_loss: 0.5356 - val_accuracy: 0.7750\n",
      "Epoch 31/100\n",
      "8167/8167 [==============================] - 249s 30ms/step - loss: 0.7854 - accuracy: 0.7132 - val_loss: 0.5335 - val_accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "8167/8167 [==============================] - 250s 31ms/step - loss: 0.7842 - accuracy: 0.7159 - val_loss: 0.5213 - val_accuracy: 0.7809\n",
      "Epoch 33/100\n",
      "8167/8167 [==============================] - 268s 33ms/step - loss: 0.7837 - accuracy: 0.7149 - val_loss: 0.5284 - val_accuracy: 0.7754\n",
      "Epoch 34/100\n",
      "8167/8167 [==============================] - 269s 33ms/step - loss: 0.7830 - accuracy: 0.7148 - val_loss: 0.5379 - val_accuracy: 0.7717\n",
      "Epoch 35/100\n",
      "8167/8167 [==============================] - 269s 33ms/step - loss: 0.7839 - accuracy: 0.7142 - val_loss: 0.5179 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "8167/8167 [==============================] - 269s 33ms/step - loss: 0.7824 - accuracy: 0.7161 - val_loss: 0.4960 - val_accuracy: 0.7945\n",
      "Epoch 37/100\n",
      "8167/8167 [==============================] - 269s 33ms/step - loss: 0.7834 - accuracy: 0.7146 - val_loss: 0.5017 - val_accuracy: 0.7904\n",
      "Epoch 38/100\n",
      "  93/8167 [..............................] - ETA: 3:55 - loss: 0.8070 - accuracy: 0.7352"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m ]\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\final_tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 12s 14ms/step - loss: 0.1599 - accuracy: 0.9645\n",
      "Test Accuracy: 0.9645\n",
      "875/875 [==============================] - 7s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.08      0.10       393\n",
      "           1       0.97      0.99      0.98     27174\n",
      "           2       0.20      0.02      0.04       433\n",
      "\n",
      "    accuracy                           0.96     28000\n",
      "   macro avg       0.44      0.37      0.37     28000\n",
      "weighted avg       0.95      0.96      0.96     28000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# 자세한 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 분포: {0: 12560, 1: 105562, 2: 12539}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"클래스 분포:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   32   351    10]\n",
      " [  182 26963    29]\n",
      " [   29   394    10]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(cm)\n",
    "# 혼동 행렬 시각화\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
