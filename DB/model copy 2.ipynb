{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import conn\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_gstc_code(code):\n",
    "    try:\n",
    "        conn.connect_to_database()\n",
    "        query = f'''\n",
    "            SELECT ts.GSTC_CODE, ts.INVEST_CODE\n",
    "              FROM TB_STOCKCLASSIFY ts\n",
    "             WHERE ts.KSTC_CODE = '{code}'\n",
    "        '''\n",
    "        \n",
    "        conn.global_cursor.execute(query)\n",
    "        df = pd.read_sql(query, conn.global_conn)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occurred while fetching data from database: {e}')\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close_database_connection()\n",
    "\n",
    "def select_data(gstc_code):\n",
    "    try:\n",
    "        conn.connect_to_database()\n",
    "        query = f'''\n",
    "            SELECT td.STCK_BSOP_DATE, td.STCK_CLPR, td.STCK_OPRC, td.STCK_HGPR, td.STCK_LWPR, td.ACML_VOL, td.ACML_TR_PBMN\n",
    "              FROM TB_DAILYSTOCK td\n",
    "             WHERE td.GSTC_CODE = '{gstc_code}'\n",
    "             ORDER BY td.STCK_BSOP_DATE DESC\n",
    "             LIMIT 100\n",
    "        '''\n",
    "        \n",
    "        conn.global_cursor.execute(query)\n",
    "        df = pd.read_sql(query, conn.global_conn)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occurred while fetching data from database: {e}')\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close_database_connection()\n",
    "\n",
    "def data_preprocess(code):\n",
    "    gstc_df = get_gstc_code(code)\n",
    "    if gstc_df is None or gstc_df.empty:\n",
    "        raise ValueError(\"GSTC_CODE를 가져올 수 없습니다.\")\n",
    "    gstc_code = gstc_df.iloc[0, 0]\n",
    "    data = select_data(gstc_code)\n",
    "    data = data.sort_values(by='STCK_BSOP_DATE', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    if data is None or data.empty:\n",
    "        raise ValueError(\"데이터를 가져올 수 없습니다.\")\n",
    "    \n",
    "    data = data.drop_duplicates(subset='STCK_BSOP_DATE')\n",
    "    \n",
    "    data['STCK_BSOP_DATE'] = pd.to_datetime(data['STCK_BSOP_DATE'], format='%Y%m%d')\n",
    "    data = data.sort_values('STCK_BSOP_DATE').reset_index(drop=True)\n",
    "\n",
    "    columns_to_convert = ['STCK_CLPR', 'STCK_OPRC', 'STCK_HGPR', 'STCK_LWPR', 'ACML_VOL', 'ACML_TR_PBMN']\n",
    "    data[columns_to_convert] = data[columns_to_convert].astype(float)\n",
    "    \n",
    "    # 이동 평균\n",
    "    data['MA5'] = data['STCK_CLPR'].rolling(window=5).mean()\n",
    "    data['MA10'] = data['STCK_CLPR'].rolling(window=10).mean()\n",
    "    data['MA20'] = data['STCK_CLPR'].rolling(window=20).mean()\n",
    "    data['MA50'] = data['STCK_CLPR'].rolling(window=50).mean()\n",
    "\n",
    "    # 지수 이동 평균\n",
    "    data['EMA5'] = data['STCK_CLPR'].ewm(span=5, adjust=False).mean()\n",
    "    data['EMA10'] = data['STCK_CLPR'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA20'] = data['STCK_CLPR'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "    # 상대 강도 지수 (RSI)\n",
    "    delta = data['STCK_CLPR'].diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -1 * delta.clip(upper=0)\n",
    "    ema_up = up.ewm(com=13, adjust=False).mean()\n",
    "    ema_down = down.ewm(com=13, adjust=False).mean()\n",
    "    rs = ema_up / ema_down\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # 이동 평균 수렴 발산 (MACD)\n",
    "    exp1 = data['STCK_CLPR'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = data['STCK_CLPR'].ewm(span=26, adjust=False).mean()\n",
    "    data['MACD'] = exp1 - exp2\n",
    "    data['MACD_signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # 볼린저 밴드\n",
    "    data['20_day_MA'] = data['STCK_CLPR'].rolling(window=20).mean()\n",
    "    data['20_day_STD'] = data['STCK_CLPR'].rolling(window=20).std()\n",
    "    data['Bollinger_High'] = data['20_day_MA'] + (data['20_day_STD'] * 2)\n",
    "    data['Bollinger_Low'] = data['20_day_MA'] - (data['20_day_STD'] * 2)\n",
    "\n",
    "    # 스토캐스틱 오실레이터\n",
    "    low14 = data['STCK_LWPR'].rolling(window=14).min()\n",
    "    high14 = data['STCK_HGPR'].rolling(window=14).max()\n",
    "    data['%K'] = 100 * ((data['STCK_CLPR'] - low14) / (high14 - low14))\n",
    "\n",
    "    data['%D'] = data['%K'].rolling(window=3).mean()\n",
    "\n",
    "    # 기술 지표 계산으로 인해 발생하는 NaN 값 제거\n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))  # [d_model/2]\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, d_model]\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_timesteps, num_features, feature_size=128, num_layers=2, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(feature_size, dropout, num_timesteps)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=feature_size, nhead=8, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.embedding = nn.Linear(num_features, feature_size)\n",
    "        self.decoder = nn.Linear(feature_size, 3)  # 출력 클래스 수를 3으로 변경\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: [batch_size, seq_len, num_features]\n",
    "        src = self.embedding(src) * np.sqrt(self.feature_size)\n",
    "        src = self.pos_encoder(src)\n",
    "        # Transformer expects input of shape (seq_len, batch_size, feature_size)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        output = self.transformer_encoder(src)\n",
    "        # 마지막 시점의 출력 사용\n",
    "        output = output[-1, :, :]\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "def load_scaler(scaler_path='./scaler.pkl'):\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return scaler\n",
    "\n",
    "def load_model(model_path='./model.pth', num_timesteps=30, num_features=22, feature_size=64, num_layers=2, dropout=0.1, device='cuda'):\n",
    "    model = TransformerModel(\n",
    "        num_timesteps=num_timesteps, \n",
    "        num_features=num_features, \n",
    "        feature_size=feature_size, \n",
    "        num_layers=num_layers, \n",
    "        dropout=dropout\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def make_prediction(code, scaler, model, device='cuda'):\n",
    "    # 데이터 전처리\n",
    "    processed_data = data_preprocess(code)\n",
    "    \n",
    "    features = processed_data.drop(['STCK_BSOP_DATE'], axis=1)\n",
    "    \n",
    "    # numpy 배열로 변환\n",
    "    features = features.values\n",
    "    \n",
    "    sequence_length = 30\n",
    "    \n",
    "    # 시퀀스 생성\n",
    "    X = []\n",
    "    for i in range(sequence_length, len(features)):\n",
    "        X.append(features[i-sequence_length:i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    X = X[-1]\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        raise ValueError(\"입력 데이터가 시퀀스 생성에 충분하지 않습니다.\")\n",
    "    \n",
    "    # 스케일링\n",
    "    num_samples, num_timesteps, num_features = X.shape\n",
    "    X_reshaped = X.reshape(-1, num_features)\n",
    "    X_scaled = scaler.transform(X_reshaped)\n",
    "    X_scaled = X_scaled.reshape(num_samples, num_timesteps, num_features)\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    return preds.cpu().numpy().tolist(), torch.softmax(outputs, 1).cpu().numpy().tolist()\n",
    "\n",
    "def prediction_to_json(code, model_path='./model.pth', scaler_path='./scaler.pkl'):\n",
    "    answer, predictions = make_prediction(code, load_scaler(scaler_path=scaler_path), load_model(model_path=model_path))\n",
    "    df = get_gstc_code(code)\n",
    "    gstc_code = df.iloc[0, 0]\n",
    "    invest_code = df.iloc[0, 1]\n",
    "    \n",
    "    result_list = []\n",
    "    result_list.append({\n",
    "        'GSTC_CODE': gstc_code,\n",
    "        'INVEST_CODE': invest_code,\n",
    "        'PREDICT_RISE_RATE': predictions[0][2],\n",
    "        'PREDICT_NO_CHANGE_RATE': predictions[0][1],\n",
    "        'PREDICT_FALL_RATE': predictions[0][0],\n",
    "        'INSERTDATE': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    })\n",
    "    \n",
    "    json_data = json.dumps(result_list, ensure_ascii=False, indent=2)\n",
    "    return json_data\n",
    "\n",
    "def insert_json_to_db(json_data):\n",
    "    try:\n",
    "        data = json.loads(json_data)\n",
    "        \n",
    "        conn.connect_to_database()\n",
    "        \n",
    "        inserted_rows = 0\n",
    "        \n",
    "        for item in data:\n",
    "            query = f'''\n",
    "                INSERT IGNORE INTO ?????????\n",
    "                (GSTC_CODE, INVEST_CODE, PREDICT_RISE_RATE, PREDICT_NO_CHANGE_RATE, PREDICT_FALL_RATE, INSERTDATE)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            '''\n",
    "            values = (\n",
    "                item['GSTC_CODE'],\n",
    "                item['INVEST_CODE'],\n",
    "                item['PREDICT_RISE_RATE'],\n",
    "                item['PREDICT_NO_CHANGE_RATE'],\n",
    "                item['PREDICT_FALL_RATE'],\n",
    "                item['INSERTDATE']\n",
    "            )\n",
    "            conn.global_cursor.execute(query, values)\n",
    "            inserted_rows += 1\n",
    "        \n",
    "        conn.commit_changes()\n",
    "        logging.info(f'{inserted_rows} rows inserted successfully')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occurred while inserting data into database: {e}')\n",
    "        conn.rollback_changes()\n",
    "    finally:\n",
    "        conn.close_database_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
